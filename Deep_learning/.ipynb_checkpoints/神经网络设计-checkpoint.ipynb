{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多分类一个隐藏层的神经网络判断XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结构\n",
    "\n",
    "X  x  V  =>> L1  x   W ==>> L2\n",
    "\n",
    "\n",
    "## 数学形式\n",
    "\n",
    "```python\n",
    "X = np.array([[1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]])\n",
    "\n",
    "#标签\n",
    "Y = np.array([[0,1,1,0]])\n",
    "\n",
    "# 权重初始化，取值范围-1到1\n",
    "V = np.random.random((3,4))*2-1\n",
    "W = np.random.random((4,1))*2-1\n",
    "\n",
    "\n",
    "#更新权重函数\n",
    "def get_update():\n",
    "    global X,Y,W,V,lr\n",
    "    \n",
    "    ##　　　随机数的前向传递　　#############\n",
    "    \n",
    "    \n",
    "    \n",
    "    # L1：输入层传递给隐藏层的值；输入层3个节点，隐藏层4个节点\n",
    "    # L2：隐藏层传递到输出层的值；输出层1个节点\n",
    "    L1 = sigmoid(np.dot(X,V))\n",
    "    L2 = sigmoid(np.dot(L1,W))\n",
    "    \n",
    "    \n",
    "    ##　　　计算传递误差　　#############\n",
    "\n",
    "    # L2_delta：输出层的误差改变量\n",
    "    # L1_delta：隐藏层的误差改变量\n",
    "    L2_delta = (Y.T - L2)*dsigmoid(L2)\n",
    "    #print(\"误差改变量1\",L2_delta,type(L2_delta))\n",
    "    L1_delta = L2_delta.dot(W.T)*dsigmoid(L1)\n",
    "    #print(\"误差改变量2\",L1_delta,type(L1_delta))\n",
    "    # W_C：输出层对隐藏层的权重改变量\n",
    "    # V_C：隐藏层对输入层的权重改变量\n",
    "    \n",
    "    ##　　　将误差反向传递给超参数　　#############\n",
    "    W_C = lr * L1.T.dot(L2_delta)\n",
    "    V_C = lr * X.T.dot(L1_delta)\n",
    "\n",
    "    # 更新后的权重\n",
    "    W = W + W_C\n",
    "    V = V + V_C\n",
    "    \n",
    "##　　　主函数更新参数　　#############    \n",
    "def main():\n",
    "    for i in range(500000):\n",
    "        get_update()\n",
    "        #if i%500 == 0:\n",
    "        #    L1 = sigmoid(np.dot(X, V))\n",
    "        #    L2 = sigmoid(np.dot(L1, W))\n",
    "        #    print('进入了for循环当前误差',np.mean(np.abs(Y.T - L2)))\n",
    "    L1 = sigmoid(np.dot(X, V))\n",
    "    L2 = sigmoid(np.dot(L1, W))\n",
    "    print('最后逼近值：',L2,L1)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############\n",
      "最后逼近值： [[0.00156547]\n",
      " [0.99430442]\n",
      " [0.99426684]\n",
      " [0.00706866]] [[0.84860258 0.64193565 0.74924555 0.67726765]\n",
      " [0.02776108 0.98959193 0.99986602 0.98933684]\n",
      " [0.99994004 0.9910515  0.0310558  0.99122012]\n",
      " [0.98836511 0.99982977 0.98766228 0.9997997 ]]\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "lr = 0.11        #学习速率\n",
    "\n",
    "#输入数据分别:偏置值,x1,x2\n",
    "X = np.array([[1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]])\n",
    "\n",
    "#标签\n",
    "Y = np.array([[0,1,1,0]])\n",
    "\n",
    "# 权重初始化，取值范围-1到1\n",
    "V = np.random.random((3,4))*2-1\n",
    "W = np.random.random((4,1))*2-1\n",
    "#print('输入层连接隐藏层的权值V：',V)\n",
    "#print('隐藏层连接输出层的权值W：',W)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "#更新权重函数\n",
    "def get_update():\n",
    "    global X,Y,W,V,lr\n",
    "    # L1：输入层传递给隐藏层的值；输入层3个节点，隐藏层4个节点\n",
    "    # L2：隐藏层传递到输出层的值；输出层1个节点\n",
    "    L1 = sigmoid(np.dot(X,V))\n",
    "    L2 = sigmoid(np.dot(L1,W))\n",
    "\n",
    "    # L2_delta：输出层的误差改变量\n",
    "    # L1_delta：隐藏层的误差改变量\n",
    "    L2_delta = (Y.T - L2)*dsigmoid(L2)\n",
    "    #print(\"误差改变量1\",L2_delta,type(L2_delta))\n",
    "    L1_delta = L2_delta.dot(W.T)*dsigmoid(L1)\n",
    "    #print(\"误差改变量2\",L1_delta,type(L1_delta))\n",
    "    # W_C：输出层对隐藏层的权重改变量\n",
    "    # V_C：隐藏层对输入层的权重改变量\n",
    "    W_C = lr * L1.T.dot(L2_delta)\n",
    "    V_C = lr * X.T.dot(L1_delta)\n",
    "\n",
    "    # 更新后的权重\n",
    "    W = W + W_C\n",
    "    V = V + V_C\n",
    "\n",
    "def main():\n",
    "    for i in range(500000):\n",
    "        get_update()\n",
    "        #if i%500 == 0:\n",
    "        #    L1 = sigmoid(np.dot(X, V))\n",
    "        #    L2 = sigmoid(np.dot(L1, W))\n",
    "        #    print('进入了for循环当前误差',np.mean(np.abs(Y.T - L2)))\n",
    "    L1 = sigmoid(np.dot(X, V))\n",
    "    L2 = sigmoid(np.dot(L1, W))\n",
    "    print('最后逼近值：',L2,L1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"#############\")\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层神经网络一个输出（回归）\n",
    "[相关解读](https://blog.csdn.net/weixin_40432828/article/details/82192709)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from numpy import *\n",
    " \n",
    " \n",
    "######## 数据集 ########\n",
    " \n",
    "p_s = [[1,1,2],[1,2,3],[2,1,6],[5,2,5],[8,3,4],[7,7,4],[7,7,7],[13,8,3],[6,10,11],[13,0,17],[14,7,12]]              # 用来训练的数据集 x\n",
    "t_s = [[2],[6],[12],[50],[96],[196],[343],[312],[660],[0],[1176]]   # 用来训练的数据集 y\n",
    " \n",
    "p_t = [[6,9,1017],[2,3,4],[5,9,10]]      # 用来测试的数据集 x_test    \n",
    "t_t = [[54918],[24],[450]]               # 用来测试的数据集 对应的实际结果 y_test                                                                        \n",
    " \n",
    "######## 超参数设定 ########\n",
    " \n",
    "n_epoch = 20000             # 训练次数\n",
    " \n",
    "HNum = 2;                   # 各层隐藏层节点数\n",
    " \n",
    "HCNum = 2;                  # 隐藏层层数\n",
    " \n",
    "AFKind = 3;                 # 激励函数种类\n",
    "emax = 0.01;                # 最大允许均方差根\n",
    "LearnRate = 0.01;           # 学习率\n",
    " \n",
    "######## 中间变量设定 ########\n",
    "TNum = 7;                   # 特征层节点数 (特征数)\n",
    " \n",
    "SNum = len(p_s);            # 样本数\n",
    " \n",
    "INum = len(p_s[0]);         # 输入层节点数（每组数据的维度）\n",
    "ONum = len(t_s[0]);         # 输出层节点数（结果的维度）\n",
    "StudyTime = 0;              # 学习次数\n",
    "KtoOne = 0.0;               # 归一化系数\n",
    "e = 0.0;                    # 均方差跟\n",
    " \n",
    "######################################################### 主要矩阵设定 ######################################################\n",
    " \n",
    "I = zeros(INum);\n",
    " \n",
    "Ti = zeros(TNum);\n",
    "To = zeros(TNum);\n",
    " \n",
    "Hi = zeros((HCNum,HNum));\n",
    "Ho = zeros((HCNum,HNum));\n",
    " \n",
    "Oi = zeros(ONum);\n",
    "Oo = zeros(ONum);\n",
    " \n",
    "Teacher = zeros(ONum);\n",
    " \n",
    "u = 0.2*ones((TNum,HNum))                  # 初始化 权值矩阵u\n",
    "w = 0.2*ones(((HCNum-1,HNum,HNum)))        # 初始化 权值矩阵w\n",
    "v = 0.2*ones((HNum,ONum))                  # 初始化 权值矩阵v\n",
    " \n",
    "dw = zeros((HCNum-1,HNum,HNum))\n",
    " \n",
    "Hb = zeros((HCNum,HNum));\n",
    "Ob = zeros(ONum);\n",
    " \n",
    "He = zeros((HCNum,HNum));\n",
    "Oe = zeros(ONum);\n",
    " \n",
    "p_s = array(p_s)\n",
    "t_s = array(t_s)\n",
    "p_t = array(p_t)\n",
    " \n",
    "################################# 时间参数 #########################################\n",
    " \n",
    "time_start = 0.0\n",
    "time_gyuyihua = 0.0\n",
    "time_nnff = 0.0\n",
    "time_nnbp = 0.0\n",
    "time_begin = 0.0\n",
    " \n",
    "time_start2 = 0.0\n",
    " \n",
    "time_nnff1 = 0.0\n",
    "time_nnff2 = 0.0\n",
    "time_nnbp_v = 0.0\n",
    "time_nnbp_w = 0.0\n",
    "time_nnbp_u = 0.0\n",
    "time_nnbp_b = 0.0\n",
    " \n",
    " \n",
    " \n",
    "######################################################### 方法 #######################################################\n",
    " \n",
    "def Calcu_KtoOne(p,t):                         # 确定归一化系数\n",
    "\tp_max = p.max();\n",
    "\tt_max = t.max();\n",
    "\treturn max(p_max,t_max);\n",
    "\t\n",
    "def trait(p):                                  # 特征化\n",
    "\tt = zeros((p.shape[0],TNum));\n",
    "\tfor i in range(0,p.shape[0],1):\n",
    "\t\tt[i,0] = p[i,0]*p[i,1]*p[i,2]\n",
    "\t\tt[i,1] = p[i,0]*p[i,1]\n",
    "\t\tt[i,2] = p[i,0]*p[i,2]\n",
    "\t\tt[i,3] = p[i,1]*p[i,2]\n",
    "\t\tt[i,4] = p[i,0]\n",
    "\t\tt[i,5] = p[i,1]\n",
    "\t\tt[i,6] = p[i,2]\n",
    "\t\n",
    "\treturn t\n",
    "\t\n",
    "def AF(p,kind):   # 激励函数\n",
    "\tt = []\n",
    "\tif kind == 1:   # sigmoid\n",
    "\t\tpass\n",
    "\telif kind == 2:   # tanh\n",
    "\t\tpass\n",
    "\telif kind == 3:    # ReLU\n",
    " \n",
    "\t\treturn where(p<0,0,p)\n",
    "\telse:\n",
    "\t\tpass\n",
    " \n",
    " \n",
    "\t\t\n",
    "def dAF(p,kind):   # 激励函数导数\n",
    "\tt = []\n",
    "\tif kind == 1:   # sigmoid\n",
    "\t\tpass\n",
    "\telif kind == 2:   # tanh\n",
    "\t\tpass\n",
    "\telif kind == 3:    # ReLU\n",
    "\t\t\n",
    "\t\treturn where(p<0,0,1) \n",
    "\telse:\n",
    "\t\tpass\n",
    " \n",
    "\t\t\n",
    "\t\t\n",
    "def nnff(p,t):\n",
    "\tpass\n",
    "\t\n",
    "def nnbp(p,t):\n",
    "\tpass\n",
    "\t\n",
    " \n",
    "def train(p,t):                                # 训练\n",
    "\t\n",
    "\tglobal e\n",
    "\tglobal v\n",
    "\tglobal w\n",
    "\tglobal dw\n",
    "\tglobal u\t\n",
    "\tglobal I \n",
    "\tglobal Ti \n",
    "\tglobal To \n",
    "\tglobal Hi \n",
    "\tglobal Ho \n",
    "\tglobal Oi \n",
    "\tglobal Oo \n",
    "\tglobal Teacher \n",
    "\tglobal Hb \n",
    "\tglobal Ob \n",
    "\tglobal He \n",
    "\tglobal Oe\n",
    "\tglobal StudyTime\n",
    "\tglobal KtoOne\n",
    "\t\n",
    "\tglobal time_start\n",
    "\tglobal time_gyuyihua\n",
    "\tglobal time_nnff\n",
    "\tglobal time_nnbp\t\n",
    "\tglobal time_start2\n",
    "\tglobal time_nnff1\n",
    "\tglobal time_nnff2\n",
    "\tglobal time_nnbp_v\n",
    "\tglobal time_nnbp_w\n",
    "\tglobal time_nnbp_u\n",
    "\tglobal time_nnbp_b\n",
    "\t\n",
    "\t\n",
    "\ttime_start = time.clock()\n",
    "\t\n",
    "\t\n",
    "\te = 0.0\n",
    "\tp = trait(p)\n",
    "\t\t\n",
    "\tKtoOne = Calcu_KtoOne(p,t)\n",
    "\t\n",
    "\ttime_gyuyihua += (time.clock()-time_start)\n",
    "\t\n",
    "\ttime_start = time.clock()\n",
    "\t\t\n",
    "\tfor isamp in range(0,SNum,1):\n",
    "\t\tTo = p[isamp]/KtoOne\n",
    "\t\tTeacher = t[isamp]/KtoOne\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t################ 前向 nnff #############################\n",
    "\t\t\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t######## 计算各层隐藏层输入输出 Hi Ho ########\n",
    "\t\t\n",
    "\t\tfor k in range(0,HCNum,1):\n",
    "\t\t\tif k == 0:\n",
    "\t\t\t\tHi[k] = dot(To,u)\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\telse:\n",
    "\t\t\t\tHi[k] = dot(Ho[k-1],w[k-1])\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\ttime_nnff1 += (time.clock()-time_start2)\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t########   计算输出层输入输出 Oi Oo    ########\n",
    "\t\tOi = dot(Ho[HCNum-1],v)\n",
    "\t\tOo = AF(add(Oi,Ob),AFKind)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\ttime_nnff2 += (time.clock()-time_start2)\t\n",
    "\t\ttime_start2 = time.clock()\t\n",
    "\t\ttime_nnff += (time.clock()-time_start)\t\n",
    "\t\ttime_start = time.clock()\n",
    "\t\t\t\t\n",
    "\t\t################ 反向 nnbp #############################\n",
    "\t\t\n",
    "\t\t######## 反向更新 v ############\n",
    "\t\t\n",
    "\t\tOe = subtract(Teacher,Oo)\n",
    "\t\tOe = multiply(Oe,dAF(add(Oi,Ob),AFKind))\n",
    "\t\t\t\t\t\t\n",
    "\t\te += sum(multiply(Oe,Oe))\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#### v 梯度 ####\t\t\n",
    "\t\t\n",
    "\t\tdv = dot(array([Oe]),array([Ho[HCNum-1]])).transpose()\t\t\t  # v 的梯度\n",
    " \n",
    "\t\tv = add(v,dv*LearnRate)    # 更新 v\n",
    "\t\t\n",
    "\t\ttime_nnbp_v += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t######## 反向更新 w #############\n",
    "\t\tHe = zeros((HCNum,HNum))\n",
    "\t\n",
    "\t\tfor c in range(HCNum-2,-1,-1):\n",
    "\t\t\tif c == HCNum-2:\n",
    "\t\t\t\tHe[c+1] = dot(v,Oe)\n",
    "\t\t\t\tHe[c+1] = multiply(He[c+1],dAF(add(Hi[c+1],Hb[c+1]),AFKind))\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\t#dw[c] = dot(array([He[c+1]]),array([Ho[c]]).transpose())\n",
    "\t\t\t\tdw[c] = dot(array([Ho[c]]).transpose(),array([He[c+1]]))\n",
    "\t\t\t\t#dw[c] = dw[c].transpose()  #@@@@@@ 若结果不理想，可尝试用此条语句\n",
    "\t\t\t\t\n",
    "\t\t\t\tw[c] = add(w[c],LearnRate*dw[c])\n",
    "\t\t\t\t\n",
    "\t\t\n",
    "\t\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tHe[c+1] = dot(w[c+1],He[c+2])\n",
    "\t\t\t\tHe[c+1] = multiply(He[c+1],dAF(add(Hi[c+1],Hb[c+1]),AFKind))\n",
    "\t\t\t\t\n",
    "\t\t\t\tdw[c] = dot(array([Ho[c]]).transpose(),array([He[c+1]]))\t\n",
    "\t\t\t\t\n",
    "\t\t\t\tw[c] = add(w[c],LearnRate*dw[c])\n",
    " \n",
    "\t\ttime_nnbp_w += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t######## 反向更新 u #############\n",
    "\t\t\n",
    "\t\tHe[0] = dot(w[0],He[1])\n",
    "\t\tHe[0] = multiply(He[0],dAF(add(Hi[0],Hb[0]),AFKind))\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\tdu = dot(array([To]).transpose(),array([He[0]]))\n",
    "\t\t\t\t\n",
    "\t\tu = add(u,du)\n",
    "\t\t\n",
    "\t\ttime_nnbp_u += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t######### 更新阈值 b ############\n",
    "\t\t\n",
    "\t\tOb = Ob + Oe*LearnRate\n",
    "\t\t\t\t\n",
    "\t\tHb = Hb + He*LearnRate\n",
    "\t\t\n",
    "\t\ttime_nnbp += (time.clock()-time_start)\n",
    "\t\n",
    "\t\ttime_start = time.clock()\n",
    "\t\t\n",
    "\t\ttime_nnbp_b += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\n",
    "\te = sqrt(e)\n",
    " \n",
    "\t\n",
    "def predict(p):\n",
    "\t\t\t\t\n",
    "\tp = trait(p)\n",
    "\tp = p/KtoOne\n",
    "\tp_result = zeros((p.shape[0],1))\n",
    " \n",
    "\tfor isamp in range(0,p.shape[0],1):\n",
    "\t\tfor k in range(0,HCNum,1):\n",
    "\t\t\tif k == 0:\n",
    "\t\t\t\tHi[k] = dot(p[isamp],u)\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\telse:\n",
    "\t\t\t\tHi[k] = dot(Ho[k-1],w[k-1])\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t########   计算输出层输入输出 Oi Oo    ########\n",
    "\t\tOi = dot(Ho[HCNum-1],v)\n",
    "\t\tOo = AF(add(Oi,Ob),AFKind)\n",
    "\t\tOo = Oo*KtoOne\n",
    "\t\tp_result[isamp] = Oo\n",
    "\treturn p_result\n",
    " \n",
    "\t\n",
    "time_begin = time.clock()\n",
    " \n",
    "for i in range(1,n_epoch,1):\n",
    "\tif i%1000 == 0:\n",
    "\t\tprint('已训练 %d 千次 ,误差均方差 %f'%((i/1000),e))\n",
    "\ttrain(p_s,t_s)\n",
    "print('训练完成，共训练 %d 次，误差均方差 %f'%(i,e))\n",
    " \n",
    "print('共耗时: ',time.clock()-time_begin)\n",
    " \n",
    "print()\n",
    "\t\t\n",
    "result = predict(p_t)\n",
    " \n",
    "print('模型预测结果 : ')\n",
    "for i in result:\n",
    "\tprint('%.2f'%i)\n",
    "\t\t\n",
    "print('\\n实际结果 : ')\t\n",
    "for i in t_t:\n",
    "\tprint(i)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己设计的实现XOR的神经网络架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标记程序开始运行\n",
      "计算机的学习误差 0.5004205014244872\n",
      "计算机的学习误差 0.009131101028017572\n",
      "计算机的学习误差 0.005720857134685466\n",
      "计算机的学习误差 0.004472865323461895\n",
      "计算机的学习误差 0.0037827133169063363\n",
      "计算机的学习误差 0.003331329682317817\n",
      "计算机的学习误差 0.003007369995703557\n",
      "计算机的学习误差 0.0027606529789076955\n",
      "计算机的学习误差 0.002564849171909172\n",
      "计算机的学习误差 0.0024046599943915305\n",
      "真实的数据标签 [[0 1 1 0]]\n",
      "计算机预测的结果： [[0.00221417]\n",
      " [0.99847397]\n",
      " [0.99753993]\n",
      " [0.00288181]]\n",
      "################################\n",
      "计算机学习到的参数 [[ 2.03353433  1.43600975  3.81865727]\n",
      " [-5.81253189  4.79623368 -1.62630681]\n",
      " [-5.28669218 -2.71230217 -3.86553909]] [[ 4.0298607  -6.14721281]\n",
      " [ 2.23563343 -3.419391  ]\n",
      " [-3.57792432  5.94746918]] [[-8.00364685]\n",
      " [ 9.69861289]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "设计一个神经网络结构\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "lr = 0.11        #学习速率\n",
    "#输入数据分别:偏置值,x1,x2\n",
    "X = np.array([[1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]])\n",
    "#标签\n",
    "Y = np.array([[0,1,1,0]])\n",
    "# 权重初始化，取值范围-1到1\n",
    "U0 = np.random.random((3,3))*2-1\n",
    "U1 = np.random.random((3,2))*2-1\n",
    "U2 = np.random.random((2,1))*2-1\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def dsigmoid(x):\n",
    "    return x*(1-x)\n",
    "#更新权重函数\n",
    "def get_update():\n",
    "    global X,Y,U0,U1,U2,lr\n",
    "    H1 = sigmoid(np.dot(X,U0))\n",
    "    H2 = sigmoid(np.dot(H1,U1))\n",
    "    H3 = sigmoid(np.dot(H2,U2))\n",
    "    H3_delta = (Y.T - H3)*dsigmoid(H3)\n",
    "    #print(\"误差改变量3\",H3_delta,type(H3_delta))\n",
    "    H2_delta = H3_delta.dot(U2.T)*dsigmoid(H2)\n",
    "    #print(\"误差改变量2\",H2_delta,type(H2_delta))\n",
    "    H1_delta = H2_delta.dot(U1.T)*dsigmoid(H1)\n",
    "    #print(\"误差改变量1\",H1_delta,type(H1_delta))\n",
    "\n",
    "    # U_C：输出层对隐藏层的权重改变量\n",
    "\n",
    "    U2_C = lr * H2.T.dot(H3_delta)\n",
    "    U1_C = lr * H1.T.dot(H2_delta)\n",
    "    U0_C = lr * X.T.dot(H1_delta)\n",
    "\n",
    "    # 更新后的权重\n",
    "    U2 = U2 + U2_C\n",
    "    U1 = U1 + U1_C\n",
    "    U0 = U0 + U0_C\n",
    "\n",
    "def main():\n",
    "    for i in range(500000):\n",
    "        get_update()\n",
    "        if i%50000 == 0:\n",
    "            H1 = sigmoid(np.dot(X,U0))\n",
    "            H2 = sigmoid(np.dot(H1,U1))\n",
    "            H3 = sigmoid(np.dot(H2,U2))\n",
    "            print('计算机的学习误差',np.mean(np.abs(Y.T - H3)))\n",
    "    H1 = sigmoid(np.dot(X,U0))\n",
    "    H2 = sigmoid(np.dot(H1,U1))\n",
    "    H3 = sigmoid(np.dot(H2,U2))\n",
    "    \n",
    "    print('真实的数据标签',Y)\n",
    "    print('计算机预测的结果：',H3)\n",
    "    print('################################')\n",
    "    print('计算机学习到的参数',U0,U1,U2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"标记程序开始运行\")\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow 实现一个ＭＬＰ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-444422cca5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "# seaborn非必需\n",
    "import seaborn\n",
    "# 如果不是在Jupyter Notebook上运行的话请注释掉下面这句\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def unpickle(filename):\n",
    "    ''' 解压数据 '''\n",
    "    with open(filename) as f:\n",
    "        # for python3 \n",
    "        # d = pickle.load(f, encoding='latin1')\n",
    "        d = pickle.load(f)\n",
    "        return d\n",
    "\n",
    "\n",
    "def onehot(labels):\n",
    "    ''' one-hot 编码 '''\n",
    "    n_sample = len(labels)\n",
    "    n_class = max(labels) + 1\n",
    "    onehot_labels = np.zeros((n_sample, n_class))\n",
    "    onehot_labels[np.arange(n_sample), labels] = 1\n",
    "\n",
    "    return onehot_labels\n",
    "\n",
    "# 读取数据\n",
    "data1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "data2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "data3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "data4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "data5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "\n",
    "X_train = np.concatenate((data1['data'], data2['data'], data3['data'], data4['data'], data5['data']), axis=0)\n",
    "label = np.concatenate((data1['labels'], data2['labels'], data3['labels'], data4['labels'], data5['labels']), axis=0)\n",
    "y_train = onehot(label)\n",
    "\n",
    "test = unpickle('cifar-10-batches-py/test_batch')\n",
    "X_test = test['data']\n",
    "y_test = onehot(test['labels'])\n",
    "\n",
    "# 设置模型参数\n",
    "learning_rate = 0.001\n",
    "training_epochs = 500\n",
    "batch_size = 500\n",
    "display_step = 1\n",
    "n_sample = X_train.shape[0]\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 1024\n",
    "n_hidden_3 = 1024\n",
    "n_class = y_train.shape[1]\n",
    "\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_class])\n",
    "\n",
    "\n",
    "def multiplayer_perceptron(x, weight, bias):\n",
    "\n",
    "    layer1 = tf.add(tf.matmul(x, weight['h1']), bias['h1'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.add(tf.matmul(layer1, weight['h2']), bias['h2'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    layer3 = tf.add(tf.matmul(layer2, weight['h3']), bias['h3'])\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "    out_layer = tf.add(tf.matmul(layer3, weight['out']), bias['out'])\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "weight = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])), \n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, n_class]))\n",
    "}\n",
    "bias = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_3])), \n",
    "    'out': tf.Variable(tf.random_normal([n_class]))\n",
    "}\n",
    "\n",
    "# 建立模型\n",
    "pred = multiplayer_perceptron(x, weight, bias)\n",
    "\n",
    "# 定义损失函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "\n",
    "# 优化\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 初始化所有变量\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "# 训练模型\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_sample / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: X_train[i*batch_size : (i+1)*batch_size, :], \n",
    "                                                          y: y_train[i*batch_size : (i+1)*batch_size, :]})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        plt.plot(epoch+1, avg_cost, 'co')\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print('Epoch:', '%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print('Opitimization Finished!')\n",
    "\n",
    "    # Test\n",
    "    acc = accuracy.eval({x: X_test, y: y_test})\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('lr=%f, te=%d, bs=%d, acc=%f' % (learning_rate, training_epochs, batch_size, acc))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cifar-10-batches-py/MLP-TF14-test.png', dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 实现神经网络的基本流程\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定义训练轮数\n",
    "training_steps = 30000\n",
    "# 定义输入的数据和对应的标签在for循环中进行填充\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "for i in range(200):\n",
    "    x1 = np.random.uniform(-1,1)\n",
    "    x2 = np.random.uniform(0,2)\n",
    "    # 这里对x1x2进行判断，如果产生的点落在半径为1的圆内，则lebel为0否则为1\n",
    "    if x1**2+x2**2<=1:\n",
    "        data.append([np.random.normal(x1,0.1),np.random.normal(x2,0.1)])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        data.append([np.random.normal(x1,0.1),np.random.normal(x2,0.1)])\n",
    "        label.append(1)\n",
    "\n",
    "\n",
    "## numpy 的hstack 函数用于在水平方向上将元素堆叠起来,reshap函数的参数为-1表示进行翻转\n",
    "\n",
    "# 这样data 200*2  label 200*1\n",
    "data = np.hstack(data).reshape(-1,2)\n",
    "label = np.hstack(label).reshape(-1,1)\n",
    "# 定义完成前向传播的隐藏层\n",
    "\n",
    "def hidden_layer(input_tensor,weight1,bias1,weight2,bias2,weight3,bias3):\n",
    "    layer1 = tf.nn.relu(tf.matmul(input_tensor,weight1)+bias1)\n",
    "    layer2 = tf.nn.relu(tf.matmul(layer1,weight2)+bias2)\n",
    "    return tf.matmul(layer2,weight3)+bias3\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=(None,2),name = \"x-input\")\n",
    "\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1),name=\"y-output\")\n",
    "\n",
    "\n",
    "\n",
    "# 定义权重参数和偏置参数\n",
    "\n",
    "weight1 = tf.Variable(tf.truncated_normal([2,10],stddev=0.1))\n",
    "bias1 = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "weight2 = tf.Variable(tf.truncated_normal([10,10],stddev=0.1))\n",
    "bias2 = tf.Variable(tf.constant(0.1,shape=[10]))\n",
    "weight3 = tf.Variable(tf.truncated_normal([10,1],stddev=0.1))\n",
    "bias3 = tf.Variable(tf.constant(0.1,shape=[1]))\n",
    "\n",
    "# 用len()函数计算data数组的长度\n",
    "\n",
    "sample_size = len(data)\n",
    "\n",
    "# 得到隐藏层前向传播的结果\n",
    "\n",
    "y = hidden_layer(x,weight1,bias1,weight2,bias2,weight3,bias3)\n",
    "\n",
    "# 自定义的损失函数，pow函数用于计算幂函数\n",
    "\n",
    "error_loss = tf.reduce_sum(tf.pow(y_-y,2))/sample_size\n",
    "\n",
    "tf.add_to_collection(\"losses\",error_loss)\n",
    "\n",
    "# 权重参数上实现L2正则化\n",
    "\n",
    "regularizer = tf.contrib.layers.l2_regularizer(0.01)\n",
    "regularization = regularizer(weight1)+regularizer(weight2)+regularizer(weight3)\n",
    "tf.add_to_collection(\"losses\",regularization)\n",
    "\n",
    "loss = tf.add_n(tf.get_collection(\"losses\"))\n",
    "\n",
    "# 定义一个优化器学习率,学习率固定为0.01,实际的应用中这个学习率应该打与0.01\n",
    "train_op = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    # for 循环内进行30000轮训练\n",
    "    for i in range(training_steps):\n",
    "        sess.run(train_op,feed_dict={x:data,y_:label})\n",
    "        #训练30000轮,每2000轮输出一次loss\n",
    "        if i % 2000 ==0 :\n",
    "            loss_value = sess.run(loss,feed_dict={x:data,y_:label})\n",
    "            print(\"After %d steps,mse_loss:%f\"%(i,loss_value))\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用tensorflow实现LeNet-5架构的手写数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/home/liyuan3970/Deep_workstation/data\",one_hot=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "learning_rate_decay = 0.99\n",
    "\n",
    "max_steps = 30000\n",
    "\n",
    "def hidden_layer(input_tensor,regularizer,avg_class,resuse):\n",
    "    #创建第一个卷积层，得到特征图的大小为32*32*28\n",
    "    with tf.variable_scope(\"C1-conv\",reuse=resuse):\n",
    "        conv1_weights = tf.get_variable(\"weight\",[5,5,1,32],initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        conv1_biases = tf.get_variable(\"bias\",[32],initializer = tf.constant_initializer(0.0))\n",
    "        conv1 = tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1],padding=\"SAME\")\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n",
    "    #创建第一个池化层，池化结果为32*14*14\n",
    "    with tf.name_scope(\"S2-max_pool\",):\n",
    "        pool1 = tf.nn.max_pool(relu1,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "    #创建第二个卷积层，得到特征图的大小为64*14*14.注意第一层池化后得到了32个特征图，所以输入的深度为32，我们这一层选择的卷积核数量为64，所以输出的深度是64，也就是说６４个特征图\n",
    "\n",
    "    with tf.variable_scope(\"C3-conv\",reuse=resuse):\n",
    "        conv2_weights = tf.get_variable(\"weight\",[5,5,32,64],initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        conv2_biases = tf.get_variable(\"bias\",[64],initializer=tf.constant_initializer(0.0))\n",
    "        conv2 = tf.nn.conv2d(pool1,conv2_weights,strides=[1,1,1,1],padding=\"SAME\")\n",
    "        relu2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n",
    "    #创建第二个池化层，池化后的结果为64*7*7\n",
    "    with tf.name_scope(\"S4-max_pool\",):\n",
    "        pool2 = tf.nn.max_pool(relu2,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "        #使用get_shape()函数可以得到这一层的维度信息，由于每一层的输入输出都是一个batch的矩阵，所以通过get_shape()函数得到的维度会包含这个batch\n",
    "        #数据的个数信息shape[1]是长度方向，2是宽度方向，3是深度方向\n",
    "        #shape 1是一个batch中数据的个数，reshape的原型是reshape(tensor,shape,name)\n",
    "        shape = pool2.get_shape().as_list()\n",
    "        nodes = shape[1]*shape[2]*shape[3] #node  = 7*7*64=3136\n",
    "        reshaped = tf.reshape(pool2,[shape[0],nodes])\n",
    "    #创建第一个全连接层\n",
    "    with tf.variable_scope(\"layer5-full\",reuse =resuse):\n",
    "        Full_connection1_weights = tf.get_variable(\"weight\",[nodes,512],initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        #对全连层的权重加入正则化\n",
    "        tf.add_to_collection(\"losses\",regularizer(Full_connection1_weights))\n",
    "        Full_connection1_biases =  tf.get_variable(\"bias\",[512],initializer=tf.constant_initializer(0.1))\n",
    "        if avg_class == None :\n",
    "            Full_1=tf.nn.relu(tf.matmul(reshaped,Full_connection1_weights)+Full_connection1_biases)\n",
    "        else:\n",
    "            Full_1 = tf.nn.relu(tf.matmul(reshaped,avg_class.average(Full_connection1_weights))+avg_class.average(Full_connection1_biases))\n",
    "    #创建第二个全连接层\n",
    "    with tf.variable_scope(\"layer6-full2\",reuse =\tresuse):\n",
    "        Full_connection2_weights = tf.get_variable(\"weight\",[512,10],initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        #对全连接层的权重加入正则化\n",
    "        tf.add_to_collection(\"losses\",regularizer(Full_connection2_weights))\n",
    "        Full_connection2_biases = tf.get_variable(\"bias\",[10],initializer = tf.constant_initializer(0.1))\n",
    "        if avg_class == None:\n",
    "            result = tf.matmul(Full_1,Full_connection2_weights)+Full_connection2_biases\n",
    "        else:\n",
    "            result = tf.matmul(Full_1,avg_class.average(Full_connection2_weights)+avg_class.average(Full_connection2_biases))\n",
    "    return result\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32,[batch_size,28,28,1],name = \"x-input\")\n",
    "\n",
    "y_ = tf.placeholder(tf.float32,[None,10],name = \"y-input\")\n",
    "\n",
    "regularizer = tf.contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "\n",
    "#注意reuse参数取值为False\n",
    "\n",
    "y = hidden_layer(x,regularizer,avg_class=None,resuse = False)\n",
    "\n",
    "training_step = tf.Variable(0,trainable = False)\n",
    "\n",
    "variable_averages = tf.train.ExponentialMovingAverage(0.99,training_step)\n",
    "\n",
    "variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "#注意resue的值为True\n",
    "\n",
    "average_y = hidden_layer(x,regularizer,variable_averages,resuse= True)\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y,labels = tf.argmax(y_,1))\n",
    "\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(learning_rate,training_step,batch_size,learning_rate_decay,staircase = True)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=training_step)\n",
    "\n",
    "with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "crorent_predicition = tf.equal(tf.arg_max(average_y,1),tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(crorent_predicition,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(max_steps):\n",
    "        if i %1000==0:\n",
    "            x_val,y_val = mnist.validation.next_batch(batch_size)\n",
    "            reshaped_x2 = np.reshape(x_val,(batch_size,28,28,1))\n",
    "            validate_feed = {x:reshaped_x2,y_:y_val}\n",
    "            validate_accuracy = sess.run(accuracy,feed_dict = validate_feed)\n",
    "            print(\"After %d training steps ,validation accury using average model is %g%%\" %(i,validate_accuracy*100))\n",
    "        x_train,y_train = mnist.train.next_batch(batch_size)\n",
    "        # 用于训练的数据需要reshape处理\n",
    "        reshaped_xs = np.reshape(x_train,(batch_size,28,28,1))\n",
    "        sess.run(train_op,feed_dict={x:reshaped_xs,y_:y_train})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow 实现单变量的时间序列的预测LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimators\n",
    "from tensorflow.contrib.timeseries.python.timeseries import model as ts_model\n",
    "from tensorflow.contrib.timeseries.python.timeseries import  NumpyReader\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class _LSTMModel(ts_model.SequentialTimeSeriesModel):\n",
    "  \"\"\"A time series model-building example using an RNNCell.\"\"\"\n",
    "\n",
    "  def __init__(self, num_units, num_features, dtype=tf.float32):\n",
    "    \"\"\"Initialize/configure the model object.\n",
    "    Note that we do not start graph building here. Rather, this object is a\n",
    "    configurable factory for TensorFlow graphs which are run by an Estimator.\n",
    "    Args:\n",
    "      num_units: The number of units in the model's LSTMCell.\n",
    "      num_features: The dimensionality of the time series (features per\n",
    "        timestep).\n",
    "      dtype: The floating point data type to use.\n",
    "    \"\"\"\n",
    "    super(_LSTMModel, self).__init__(\n",
    "        # Pre-register the metrics we'll be outputting (just a mean here).\n",
    "        train_output_names=[\"mean\"],\n",
    "        predict_output_names=[\"mean\"],\n",
    "        num_features=num_features,\n",
    "        dtype=dtype)\n",
    "    self._num_units = num_units\n",
    "    # Filled in by initialize_graph()\n",
    "    self._lstm_cell = None\n",
    "    self._lstm_cell_run = None\n",
    "    self._predict_from_lstm_output = None\n",
    "\n",
    "  def initialize_graph(self, input_statistics):\n",
    "    \"\"\"Save templates for components, which can then be used repeatedly.\n",
    "    This method is called every time a new graph is created. It's safe to start\n",
    "    adding ops to the current default graph here, but the graph should be\n",
    "    constructed from scratch.\n",
    "    Args:\n",
    "      input_statistics: A math_utils.InputStatistics object.\n",
    "    \"\"\"\n",
    "    super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)\n",
    "    self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)\n",
    "    # Create templates so we don't have to worry about variable reuse.\n",
    "    self._lstm_cell_run = tf.make_template(\n",
    "        name_=\"lstm_cell\",\n",
    "        func_=self._lstm_cell,\n",
    "        create_scope_now_=True)\n",
    "    # Transforms LSTM output into mean predictions.\n",
    "    self._predict_from_lstm_output = tf.make_template(\n",
    "        name_=\"predict_from_lstm_output\",\n",
    "        func_=lambda inputs: tf.layers.dense(inputs=inputs, units=self.num_features),\n",
    "        create_scope_now_=True)\n",
    "\n",
    "  def get_start_state(self):\n",
    "    \"\"\"Return initial state for the time series model.\"\"\"\n",
    "    return (\n",
    "        # Keeps track of the time associated with this state for error checking.\n",
    "        tf.zeros([], dtype=tf.int64),\n",
    "        # The previous observation or prediction.\n",
    "        tf.zeros([self.num_features], dtype=self.dtype),\n",
    "        # The state of the RNNCell (batch dimension removed since this parent\n",
    "        # class will broadcast).\n",
    "        [tf.squeeze(state_element, axis=0)\n",
    "         for state_element\n",
    "         in self._lstm_cell.zero_state(batch_size=1, dtype=self.dtype)])\n",
    "\n",
    "  def _transform(self, data):\n",
    "    \"\"\"Normalize data based on input statistics to encourage stable training.\"\"\"\n",
    "    mean, variance = self._input_statistics.overall_feature_moments\n",
    "    return (data - mean) / variance\n",
    "\n",
    "  def _de_transform(self, data):\n",
    "    \"\"\"Transform data back to the input scale.\"\"\"\n",
    "    mean, variance = self._input_statistics.overall_feature_moments\n",
    "    return data * variance + mean\n",
    "\n",
    "  def _filtering_step(self, current_times, current_values, state, predictions):\n",
    "    \"\"\"Update model state based on observations.\n",
    "    Note that we don't do much here aside from computing a loss. In this case\n",
    "    it's easier to update the RNN state in _prediction_step, since that covers\n",
    "    running the RNN both on observations (from this method) and our own\n",
    "    predictions. This distinction can be important for probabilistic models,\n",
    "    where repeatedly predicting without filtering should lead to low-confidence\n",
    "    predictions.\n",
    "    Args:\n",
    "      current_times: A [batch size] integer Tensor.\n",
    "      current_values: A [batch size, self.num_features] floating point Tensor\n",
    "        with new observations.\n",
    "      state: The model's state tuple.\n",
    "      predictions: The output of the previous `_prediction_step`.\n",
    "    Returns:\n",
    "      A tuple of new state and a predictions dictionary updated to include a\n",
    "      loss (note that we could also return other measures of goodness of fit,\n",
    "      although only \"loss\" will be optimized).\n",
    "    \"\"\"\n",
    "    state_from_time, prediction, lstm_state = state\n",
    "    with tf.control_dependencies(\n",
    "            [tf.assert_equal(current_times, state_from_time)]):\n",
    "      transformed_values = self._transform(current_values)\n",
    "      # Use mean squared error across features for the loss.\n",
    "      predictions[\"loss\"] = tf.reduce_mean(\n",
    "          (prediction - transformed_values) ** 2, axis=-1)\n",
    "      # Keep track of the new observation in model state. It won't be run\n",
    "      # through the LSTM until the next _imputation_step.\n",
    "      new_state_tuple = (current_times, transformed_values, lstm_state)\n",
    "    return (new_state_tuple, predictions)\n",
    "\n",
    "  def _prediction_step(self, current_times, state):\n",
    "    \"\"\"Advance the RNN state using a previous observation or prediction.\"\"\"\n",
    "    _, previous_observation_or_prediction, lstm_state = state\n",
    "    lstm_output, new_lstm_state = self._lstm_cell_run(\n",
    "        inputs=previous_observation_or_prediction, state=lstm_state)\n",
    "    next_prediction = self._predict_from_lstm_output(lstm_output)\n",
    "    new_state_tuple = (current_times, next_prediction, new_lstm_state)\n",
    "    return new_state_tuple, {\"mean\": self._de_transform(next_prediction)}\n",
    "\n",
    "  def _imputation_step(self, current_times, state):\n",
    "    \"\"\"Advance model state across a gap.\"\"\"\n",
    "    # Does not do anything special if we're jumping across a gap. More advanced\n",
    "    # models, especially probabilistic ones, would want a special case that\n",
    "    # depends on the gap size.\n",
    "    return state\n",
    "\n",
    "  def _exogenous_input_step(\n",
    "          self, current_times, current_exogenous_regressors, state):\n",
    "    \"\"\"Update model state based on exogenous regressors.\"\"\"\n",
    "    raise NotImplementedError(\n",
    "        \"Exogenous inputs are not implemented for this example.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  x = np.array(range(1000))\n",
    "  noise = np.random.uniform(-0.2, 0.2, 1000)\n",
    "  y = np.sin(np.pi * x / 50 ) + np.cos(np.pi * x / 50) + np.sin(np.pi * x / 25) + noise\n",
    "\n",
    "  data = {\n",
    "      tf.contrib.timeseries.TrainEvalFeatures.TIMES: x,\n",
    "      tf.contrib.timeseries.TrainEvalFeatures.VALUES: y,\n",
    "  }\n",
    "\n",
    "  reader = NumpyReader(data)\n",
    "\n",
    "  train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(\n",
    "      reader, batch_size=4, window_size=100)\n",
    "\n",
    "  estimator = ts_estimators.TimeSeriesRegressor(\n",
    "      model=_LSTMModel(num_features=1, num_units=128),\n",
    "      optimizer=tf.train.AdamOptimizer(0.001))\n",
    "\n",
    "  estimator.train(input_fn=train_input_fn, steps=2000)\n",
    "  evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)\n",
    "  evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)\n",
    "  # Predict starting after the evaluation\n",
    "  (predictions,) = tuple(estimator.predict(\n",
    "      input_fn=tf.contrib.timeseries.predict_continuation_input_fn(\n",
    "          evaluation, steps=200)))\n",
    "\n",
    "  observed_times = evaluation[\"times\"][0]\n",
    "  observed = evaluation[\"observed\"][0, :, :]\n",
    "  evaluated_times = evaluation[\"times\"][0]\n",
    "  evaluated = evaluation[\"mean\"][0]\n",
    "  predicted_times = predictions['times']\n",
    "  predicted = predictions[\"mean\"]\n",
    "\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  plt.axvline(999, linestyle=\"dotted\", linewidth=4, color='r')\n",
    "  observed_lines = plt.plot(observed_times, observed, label=\"observation\", color=\"k\")\n",
    "  evaluated_lines = plt.plot(evaluated_times, evaluated, label=\"evaluation\", color=\"g\")\n",
    "  predicted_lines = plt.plot(predicted_times, predicted, label=\"prediction\", color=\"r\")\n",
    "  plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],\n",
    "             loc=\"upper left\")\n",
    "  plt.savefig('predict_result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow实现多变量的LSTM预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from os import path\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.timeseries.python.timeseries import estimators as ts_estimators\n",
    "from tensorflow.contrib.timeseries.python.timeseries import model as ts_model\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class _LSTMModel(ts_model.SequentialTimeSeriesModel):\n",
    "  \"\"\"A time series model-building example using an RNNCell.\"\"\"\n",
    "\n",
    "  def __init__(self, num_units, num_features, dtype=tf.float32):\n",
    "    \"\"\"Initialize/configure the model object.\n",
    "    Note that we do not start graph building here. Rather, this object is a\n",
    "    configurable factory for TensorFlow graphs which are run by an Estimator.\n",
    "    Args:\n",
    "      num_units: The number of units in the model's LSTMCell.\n",
    "      num_features: The dimensionality of the time series (features per\n",
    "        timestep).\n",
    "      dtype: The floating point data type to use.\n",
    "    \"\"\"\n",
    "    super(_LSTMModel, self).__init__(\n",
    "        # Pre-register the metrics we'll be outputting (just a mean here).\n",
    "        train_output_names=[\"mean\"],\n",
    "        predict_output_names=[\"mean\"],\n",
    "        num_features=num_features,\n",
    "        dtype=dtype)\n",
    "    self._num_units = num_units\n",
    "    # Filled in by initialize_graph()\n",
    "    self._lstm_cell = None\n",
    "    self._lstm_cell_run = None\n",
    "    self._predict_from_lstm_output = None\n",
    "\n",
    "  def initialize_graph(self, input_statistics):\n",
    "    \"\"\"Save templates for components, which can then be used repeatedly.\n",
    "    This method is called every time a new graph is created. It's safe to start\n",
    "    adding ops to the current default graph here, but the graph should be\n",
    "    constructed from scratch.\n",
    "    Args:\n",
    "      input_statistics: A math_utils.InputStatistics object.\n",
    "    \"\"\"\n",
    "    super(_LSTMModel, self).initialize_graph(input_statistics=input_statistics)\n",
    "    self._lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=self._num_units)\n",
    "    # Create templates so we don't have to worry about variable reuse.\n",
    "    self._lstm_cell_run = tf.make_template(\n",
    "        name_=\"lstm_cell\",\n",
    "        func_=self._lstm_cell,\n",
    "        create_scope_now_=True)\n",
    "    # Transforms LSTM output into mean predictions.\n",
    "    self._predict_from_lstm_output = tf.make_template(\n",
    "        name_=\"predict_from_lstm_output\",\n",
    "        func_=lambda inputs: tf.layers.dense(inputs=inputs, units=self.num_features),\n",
    "        create_scope_now_=True)\n",
    "\n",
    "  def get_start_state(self):\n",
    "    \"\"\"Return initial state for the time series model.\"\"\"\n",
    "    return (\n",
    "        # Keeps track of the time associated with this state for error checking.\n",
    "        tf.zeros([], dtype=tf.int64),\n",
    "        # The previous observation or prediction.\n",
    "        tf.zeros([self.num_features], dtype=self.dtype),\n",
    "        # The state of the RNNCell (batch dimension removed since this parent\n",
    "        # class will broadcast).\n",
    "        [tf.squeeze(state_element, axis=0)\n",
    "         for state_element\n",
    "         in self._lstm_cell.zero_state(batch_size=1, dtype=self.dtype)])\n",
    "\n",
    "  def _transform(self, data):\n",
    "    \"\"\"Normalize data based on input statistics to encourage stable training.\"\"\"\n",
    "    mean, variance = self._input_statistics.overall_feature_moments\n",
    "    return (data - mean) / variance\n",
    "\n",
    "  def _de_transform(self, data):\n",
    "    \"\"\"Transform data back to the input scale.\"\"\"\n",
    "    mean, variance = self._input_statistics.overall_feature_moments\n",
    "    return data * variance + mean\n",
    "\n",
    "  def _filtering_step(self, current_times, current_values, state, predictions):\n",
    "    \"\"\"Update model state based on observations.\n",
    "    Note that we don't do much here aside from computing a loss. In this case\n",
    "    it's easier to update the RNN state in _prediction_step, since that covers\n",
    "    running the RNN both on observations (from this method) and our own\n",
    "    predictions. This distinction can be important for probabilistic models,\n",
    "    where repeatedly predicting without filtering should lead to low-confidence\n",
    "    predictions.\n",
    "    Args:\n",
    "      current_times: A [batch size] integer Tensor.\n",
    "      current_values: A [batch size, self.num_features] floating point Tensor\n",
    "        with new observations.\n",
    "      state: The model's state tuple.\n",
    "      predictions: The output of the previous `_prediction_step`.\n",
    "    Returns:\n",
    "      A tuple of new state and a predictions dictionary updated to include a\n",
    "      loss (note that we could also return other measures of goodness of fit,\n",
    "      although only \"loss\" will be optimized).\n",
    "    \"\"\"\n",
    "    state_from_time, prediction, lstm_state = state\n",
    "    with tf.control_dependencies(\n",
    "            [tf.assert_equal(current_times, state_from_time)]):\n",
    "      transformed_values = self._transform(current_values)\n",
    "      # Use mean squared error across features for the loss.\n",
    "      predictions[\"loss\"] = tf.reduce_mean(\n",
    "          (prediction - transformed_values) ** 2, axis=-1)\n",
    "      # Keep track of the new observation in model state. It won't be run\n",
    "      # through the LSTM until the next _imputation_step.\n",
    "      new_state_tuple = (current_times, transformed_values, lstm_state)\n",
    "    return (new_state_tuple, predictions)\n",
    "\n",
    "  def _prediction_step(self, current_times, state):\n",
    "    \"\"\"Advance the RNN state using a previous observation or prediction.\"\"\"\n",
    "    _, previous_observation_or_prediction, lstm_state = state\n",
    "    lstm_output, new_lstm_state = self._lstm_cell_run(\n",
    "        inputs=previous_observation_or_prediction, state=lstm_state)\n",
    "    next_prediction = self._predict_from_lstm_output(lstm_output)\n",
    "    new_state_tuple = (current_times, next_prediction, new_lstm_state)\n",
    "    return new_state_tuple, {\"mean\": self._de_transform(next_prediction)}\n",
    "\n",
    "  def _imputation_step(self, current_times, state):\n",
    "    \"\"\"Advance model state across a gap.\"\"\"\n",
    "    # Does not do anything special if we're jumping across a gap. More advanced\n",
    "    # models, especially probabilistic ones, would want a special case that\n",
    "    # depends on the gap size.\n",
    "    return state\n",
    "\n",
    "  def _exogenous_input_step(\n",
    "          self, current_times, current_exogenous_regressors, state):\n",
    "    \"\"\"Update model state based on exogenous regressors.\"\"\"\n",
    "    raise NotImplementedError(\n",
    "        \"Exogenous inputs are not implemented for this example.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  csv_file_name = path.join(\"./data/multivariate_periods.csv\")\n",
    "  reader = tf.contrib.timeseries.CSVReader(\n",
    "      csv_file_name,\n",
    "      column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,)\n",
    "                    + (tf.contrib.timeseries.TrainEvalFeatures.VALUES,) * 5))\n",
    "  train_input_fn = tf.contrib.timeseries.RandomWindowInputFn(\n",
    "      reader, batch_size=4, window_size=32)\n",
    "\n",
    "  estimator = ts_estimators.TimeSeriesRegressor(\n",
    "      model=_LSTMModel(num_features=5, num_units=128),\n",
    "      optimizer=tf.train.AdamOptimizer(0.001))\n",
    "\n",
    "  estimator.train(input_fn=train_input_fn, steps=200)\n",
    "  evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)\n",
    "  evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)\n",
    "  # Predict starting after the evaluation\n",
    "  (predictions,) = tuple(estimator.predict(\n",
    "      input_fn=tf.contrib.timeseries.predict_continuation_input_fn(\n",
    "          evaluation, steps=100)))\n",
    "\n",
    "  observed_times = evaluation[\"times\"][0]\n",
    "  observed = evaluation[\"observed\"][0, :, :]\n",
    "  evaluated_times = evaluation[\"times\"][0]\n",
    "  evaluated = evaluation[\"mean\"][0]\n",
    "  predicted_times = predictions['times']\n",
    "  predicted = predictions[\"mean\"]\n",
    "\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  plt.axvline(99, linestyle=\"dotted\", linewidth=4, color='r')\n",
    "  observed_lines = plt.plot(observed_times, observed, label=\"observation\", color=\"k\")\n",
    "  evaluated_lines = plt.plot(evaluated_times, evaluated, label=\"evaluation\", color=\"g\")\n",
    "  predicted_lines = plt.plot(predicted_times, predicted, label=\"prediction\", color=\"r\")\n",
    "  plt.legend(handles=[observed_lines[0], evaluated_lines[0], predicted_lines[0]],\n",
    "             loc=\"upper left\")\n",
    "  plt.savefig('predict_result.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
