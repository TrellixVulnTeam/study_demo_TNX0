{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0111 18:21:45.519686 140199244080960 deprecation.py:323] From <ipython-input-1-428ced9aadef>:12: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0111 18:21:45.521999 140199244080960 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0111 18:21:45.523706 140199244080960 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0111 18:21:46.003576 140199244080960 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0111 18:21:46.017246 140199244080960 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0111 18:21:46.154170 140199244080960 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0111 18:21:46.638164 140199244080960 deprecation.py:323] From <ipython-input-1-428ced9aadef>:54: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0111 18:21:47.087581 140199244080960 deprecation.py:323] From <ipython-input-1-428ced9aadef>:58: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0111 18:21:47.420188 140199244080960 deprecation.py:506] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0111 18:21:47.435176 140199244080960 deprecation.py:506] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0111 18:21:47.986218 140199244080960 deprecation.py:323] From <ipython-input-1-428ced9aadef>:67: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.171875\n",
      "step 20, training accuracy 0.59375\n",
      "step 40, training accuracy 0.796875\n",
      "step 60, training accuracy 0.828125\n",
      "step 80, training accuracy 0.898438\n",
      "step 100, training accuracy 0.867188\n",
      "step 120, training accuracy 0.90625\n",
      "step 140, training accuracy 0.945312\n",
      "step 160, training accuracy 0.9375\n",
      "step 180, training accuracy 0.914062\n",
      "step 200, training accuracy 0.945312\n",
      "step 220, training accuracy 0.914062\n",
      "step 240, training accuracy 0.921875\n",
      "step 260, training accuracy 0.9375\n",
      "step 280, training accuracy 0.914062\n",
      "step 300, training accuracy 0.898438\n",
      "step 320, training accuracy 0.90625\n",
      "step 340, training accuracy 0.945312\n",
      "step 360, training accuracy 0.96875\n",
      "step 380, training accuracy 0.929688\n",
      "step 400, training accuracy 0.898438\n",
      "step 420, training accuracy 0.953125\n",
      "step 440, training accuracy 0.945312\n",
      "step 460, training accuracy 0.953125\n",
      "step 480, training accuracy 0.984375\n",
      "step 500, training accuracy 0.945312\n",
      "step 520, training accuracy 0.984375\n",
      "step 540, training accuracy 0.929688\n",
      "step 560, training accuracy 0.929688\n",
      "step 580, training accuracy 0.992188\n",
      "step 600, training accuracy 0.960938\n",
      "step 620, training accuracy 0.953125\n",
      "step 640, training accuracy 0.945312\n",
      "step 660, training accuracy 0.945312\n",
      "step 680, training accuracy 0.90625\n",
      "step 700, training accuracy 0.960938\n",
      "step 720, training accuracy 0.960938\n",
      "step 740, training accuracy 0.984375\n",
      "step 760, training accuracy 0.96875\n",
      "step 780, training accuracy 0.953125\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May 13 08:55:50 2018\n",
    "\n",
    "@author: Administrator\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#在这里做数据加载，\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "\n",
    "# RNN学习时使用的参数\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 20\n",
    "\n",
    "# 神经网络的参数\n",
    "n_input = 28  # 输入层的n\n",
    "n_steps = 28  # 28长度\n",
    "n_hidden = 128  # 隐含层的特征数\n",
    "n_classes = 10  # 输出的数量，因为是分类问题，0~9个数字，这里一共有10个\n",
    "\n",
    "# 构建tensorflow的输入X的placeholder\n",
    "x = tf.placeholder(\"float32\", [None, n_steps, n_input])\n",
    "# 输出Y\n",
    "y = tf.placeholder(\"float32\", [None, n_classes])\n",
    "\n",
    "# 随机初始化每一层的权值和偏置\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),  # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.constant(0.1,shape=([n_hidden,]))),\n",
    "    'out': tf.Variable(tf.constant(0.1,shape=([n_classes,])))\n",
    "}\n",
    "\n",
    "'''\n",
    "构建RNN\n",
    "'''\n",
    "def RNN(_X,  _weights, _biases):   \n",
    "\n",
    "    _X = tf.reshape(_X, [-1, n_input])  \n",
    "    # 输入层到隐含层，第一次是直接运算\n",
    "    X_in = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "    #规则数据\n",
    "    X_in =tf.reshape(X_in,[-1,n_steps,n_hidden])\n",
    "    #之后使用LSTM\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0,state_is_tuple=True)\n",
    "    #初始化\n",
    "    init_state=lstm_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    # 开始跑RNN那部分\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, X_in, initial_state=init_state,time_major=False)\n",
    "    # 输出层\n",
    "    results=tf.matmul(final_state[1], _weights['out']) + _biases['out']\n",
    "    return results\n",
    "\n",
    "\n",
    "pred = RNN(x,  weights, biases)\n",
    "\n",
    "# 定义损失和优化方法，其中算是为softmax交叉熵，优化方法为Adam\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( logits=pred, labels=y))  # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)  # Adam Optimizer\n",
    "\n",
    "# 进行模型的评估，argmax是取出取值最大的那一个的标签作为输出\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 初始化\n",
    "init = tf.global_variables_initializer()\n",
    "# 开始运行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    # 持续迭代\n",
    "    while step * batch_size < training_iters:\n",
    "        # 随机抽出这一次迭代训练时用的数据\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 对数据进行处理，使得其符合输入\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_steps, n_input))\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                       })\n",
    "        # 在特定的迭代回合进行数据的输出\n",
    "        if step % display_step == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, })\n",
    "            print('step %d, training accuracy %g' % (step, acc))\n",
    "        step += 1\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
