{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecor数据存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "784\n",
      "55000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",\n",
    "                                  dtype=tf.uint8, one_hot=True)\n",
    "\n",
    "\n",
    "# 定义生成整数型和字符串型属性的方法，这是将数据填入到Example协议内存块\n",
    "# (protocol buffer)的第一步，以后会调用到这个方法\n",
    "def Int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def Bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "# 读取mnist数据。\n",
    "images = mnist.train.images\n",
    "\n",
    "labels = mnist.train.labels\n",
    "\n",
    "pixels = images.shape[1]\n",
    "print(pixels)\n",
    "num_examples = mnist.train.num_examples\n",
    "print(num_examples)\n",
    "#输出TFRecord文件的地址(相对于系统根目录)。\n",
    "filename = \"MNIST_tfrecords/MNIST_tfrecords\"\n",
    "\n",
    "# 创建一个python_io.TFRecordWriter()类的实例\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "# for循环执行了将数据填入到Example协议内存块的主要操作\n",
    "for i in range(num_examples):\n",
    "    # 将图像矩阵转化成一个字符串\n",
    "    image_to_string = images[i].tostring()\n",
    "\n",
    "    feature = {\n",
    "        \"pixels\": Int64_feature(pixels),\n",
    "        \"label\": Int64_feature(np.argmax(labels[i])),\n",
    "        \"image_raw\": Bytes_feature(image_to_string)\n",
    "    }\n",
    "    features = tf.train.Features(feature=feature)\n",
    "\n",
    "    # 定义一个Example，将相关信息写入到这个数据结构\n",
    "    example = tf.train.Example(features=features)\n",
    "\n",
    "    # 将一个Example写入到TFRecord文件\n",
    "    # 原型writer(self, record)\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "# 在写完文件后最好的习惯是调用close()函数关闭\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取TF数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "3\n",
      "4\n",
      "6\n",
      "1\n",
      "8\n",
      "1\n",
      "0\n",
      "9\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#创建一个TFRecordReader类的实例\n",
    "reader = tf.TFRecordReader()\n",
    "\n",
    "#创建一个队列对输入文件列表进行维护，队列的知识放到了本章的稍后\n",
    "#函数原型string_input_producer(string_tensor,num_epochs,shuffle,seed,\n",
    "#                                  capacity,shared_name,name,cancel_op)\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "                       [\"MNIST_tfrecords/MNIST_tfrecords\"])\n",
    "\n",
    "#使用TFRecordReader.read()函数从文件中读取一个样例，原型reader(self,queue,name)\n",
    "#也可使用read_up_to()函数一次性读取多个样例，\n",
    "#原型read_up_to(self,queue,num_records,name)\n",
    "_,serialized_example = reader.read(filename_queue)\n",
    "\n",
    "#使用parse_single_example()函数解析读取的样例。\n",
    "#原型parse_single_example(serialized,features,name,example_names)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        #可以使用FixedLenFeature类对属性进行解析，\n",
    "        \"image_raw\":tf.FixedLenFeature([],tf.string),\n",
    "        \"pixels\":tf.FixedLenFeature([],tf.int64),\n",
    "        \"label\":tf.FixedLenFeature([],tf.int64)\n",
    "    })\n",
    "\n",
    "#decode_raw()函数用于将字符串解析成图像对应的像素数组\n",
    "#函数原型decode_raw(bytes,out_type,little_endian,name)\n",
    "images = tf.decode_raw(features[\"image_raw\"],tf.uint8)\n",
    "#使用cast()函数进行类型转换\n",
    "labels = tf.cast(features[\"label\"],tf.int32)\n",
    "pixels = tf.cast(features[\"pixels\"],tf.int32)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #启动多线程处理输入数据，多线程处理数据也会在本章的稍后予以介绍\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "\n",
    "    for i in range(10):\n",
    "        image, label, pixel = sess.run([images, labels, pixels])\n",
    "        print(label)\n",
    "        #输出7 3 4 6 1 8 1 0 9 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1211 15:01:48.445559 140669260474176 deprecation.py:323] From <ipython-input-2-64bab3ec9496>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1211 15:01:48.446966 140669260474176 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W1211 15:01:48.448385 140669260474176 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1211 15:01:48.741093 140669260474176 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1211 15:01:48.744842 140669260474176 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W1211 15:01:48.797538 140669260474176 deprecation.py:323] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",\n",
    "                                             dtype=tf.uint8,one_hot=True)\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "images = mnist.test.images\n",
    "labels = mnist.test.labels\n",
    "pixels = images.shape[1]\n",
    "num_examples = mnist.test.num_examples\n",
    "\n",
    "#num_files定义总共写入多少个文件\n",
    "num_files = 2\n",
    "\n",
    "for i in range(num_files):\n",
    "    #将数据写入多个文件时，为区分这些文件可以添加后缀\n",
    "    filename = (\"TFRecord/data_tfrecords-%.1d-of-%.1d\"\n",
    "                                                         % (i, num_files))\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "    #将Example结构写入TFRecord文件，写入文件的过程和11.1节一样。\n",
    "    for index in range(num_examples):\n",
    "        image_string = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            \"pixels\": _int64_feature(pixels),\n",
    "            \"label\": _int64_feature(np.argmax(labels[index])),\n",
    "            \"image_raw\": _bytes_feature(image_string)\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "\n",
    "#使用match_filenames_once()函数获取符合正则表达式的所有文件\n",
    "#函数原型match_filenames_once(pattern,name)\n",
    "files = tf.train.match_filenames_once(\"TFRecord/data_tfrecords-*\")\n",
    "\n",
    "#通过string_input_producer()函数创建输入队列，输入队列的文件列表是files\n",
    "#函数原型string_input_producer(string_tensor,num_epochs,shuffle,capacity,\n",
    "#                                                  shared_name,name,cancel_op)\n",
    "#函数的shuffle参数用于指定是否随即打乱读文件的顺序，在实际问题中会设置为True\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "#解析读取的样例。\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        \"image_raw\":tf.FixedLenFeature([],tf.string),\n",
    "        \"pixels\":tf.FixedLenFeature([],tf.int64),\n",
    "        \"label\":tf.FixedLenFeature([],tf.int64)\n",
    "    })\n",
    "images = tf.decode_raw(features[\"image_raw\"],tf.uint8)\n",
    "labels = tf.cast(features[\"label\"],tf.int32)\n",
    "pixels = tf.cast(features[\"pixels\"],tf.int32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    #print(sess.run(files))\n",
    "    #打印文件列表，输出为：\n",
    "    #[b'/home/jiangziyang/TFRecord/data_tfrecords-1-of-2'\n",
    "    # b'/home/jiangziyang/TFRecord/data_tfrecords-0-of-2']\n",
    "\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "#     for i in range(6):\n",
    "#         print(sess.run([images,labels]))\n",
    "\n",
    "    coordinator.request_stop()\n",
    "    coordinator.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_16_batch_2/fifo_queue' is closed and has insufficient elements (requested 50, current size 0)\n\t [[node batch_2 (defined at <ipython-input-4-0e31e8bbd50c>:39) ]]\n\nOriginal stack trace for 'batch_2':\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/asyncio/base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-0e31e8bbd50c>\", line 39, in <module>\n    batch_size=batch_size,capacity=capacity,)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 1021, in batch\n    name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 790, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3862, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_16_batch_2/fifo_queue' is closed and has insufficient elements (requested 50, current size 0)\n\t [[{{node batch_2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0e31e8bbd50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#在每一轮训练的过程中都会执行一个组合样例为batch的操作并打印出来\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_16_batch_2/fifo_queue' is closed and has insufficient elements (requested 50, current size 0)\n\t [[node batch_2 (defined at <ipython-input-4-0e31e8bbd50c>:39) ]]\n\nOriginal stack trace for 'batch_2':\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/asyncio/base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-0e31e8bbd50c>\", line 39, in <module>\n    batch_size=batch_size,capacity=capacity,)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 1021, in batch\n    name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py\", line 790, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3862, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/liyuan3970/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "files = tf.train.match_filenames_once(\"TFRecord/data_tfrecords-*\")\n",
    "#创建文件队列shuffle参数设置为True，打乱文件\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=True)\n",
    "\n",
    "#实例化TFRecordReader类，准备读取TFRecord文件\n",
    "reader = tf.TFRecordReader()\n",
    "_,serialized_example = reader.read(filename_queue)\n",
    "\n",
    "#解析读取的样例，这部分和11.1.1节是相同的\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        \"image_raw\":tf.FixedLenFeature([],tf.string),\n",
    "        \"pixels\":tf.FixedLenFeature([],tf.int64),\n",
    "        \"label\":tf.FixedLenFeature([],tf.int64)\n",
    "    })\n",
    "images = tf.decode_raw(features[\"image_raw\"],tf.uint8)\n",
    "labels = tf.cast(features[\"label\"],tf.int32)\n",
    "pixels = tf.cast(features[\"pixels\"],tf.int32)\n",
    "\n",
    "#设置每个batch中样例的个数\n",
    "batch_size =50\n",
    "\n",
    "#用于组合成batch的队列中最多可以缓存的样例的个数\n",
    "capacity = 5000 + 3 * batch_size\n",
    "\n",
    "#set_shape()函数用来设置设置尺寸，这一步操作也可以使用image.resize_images()\n",
    "#函数来完成。设置尺寸的操作是必须的，在1.0.0版的TensorFlow中如果没有这一步\n",
    "#会在batch()函数的capacity参数处报错ValueError: All shapes must be fully\n",
    "#defined: [TensorShape([Dimension(None)]), TensorShape([])]\n",
    "images.set_shape(784)\n",
    "\n",
    "#使用batch()函数将样例组合成batch\n",
    "#函数原型batch(tensors,batch_size,num_threads,capacity,enqueue_many,shapes,\n",
    "#                        dynamic_pad,allow_smaller_final_batch,shared_name,name)\n",
    "image_batch, label_batch = tf.train.batch([images, labels],\n",
    "                                    batch_size=batch_size,capacity=capacity,)\n",
    "\n",
    "\n",
    "\n",
    "#shuffle_batch()函数会在组织样例数据成batch之前将数据顺序打乱，\n",
    "#这两个函数的使用情况类似。shuffle_batch()函数原型为\n",
    "#shuffle_batch(tensors,batch_size,capacity,min_after_dequeue,num_threads,\n",
    "#                seed,enqueue_many,shapes,allow_smaller_final_batch,shared_name,name)\n",
    "#min_after_dequeue=5000\n",
    "#image_batch, label_batch = tf.train.shuffle_batch([images, labels],\n",
    "#                                    batch_size=batch_size,capacity=capacity,\n",
    "#                                                  min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "#接下来就可以像之前的网络模型那样创建会话并开始训练了，与之前的训练过程相比，\n",
    "#这里的会话中增加了多线程处理的相关代码\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    #一般在这个循环内开始训练，这里设定了训练轮数为3\n",
    "    #在每一轮训练的过程中都会执行一个组合样例为batch的操作并打印出来\n",
    "    for i in range(3):\n",
    "        xs,ys=sess.run([image_batch,label_batch])\n",
    "        print(xs,ys)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "files = tf.train.match_filenames_once(\"TFRecord/data_tfrecords-*\")\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=True)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        \"image_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"pixels\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "images = tf.decode_raw(features[\"image_raw\"], tf.uint8)\n",
    "labels = tf.cast(features[\"label\"], tf.int32)\n",
    "pixels = tf.cast(features[\"pixels\"], tf.int32)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "capacity = 5000 + 3 * batch_size\n",
    "\n",
    "images.set_shape(784)\n",
    "\n",
    "# 使用shuffle_batch()函数在组织样例数据成batch之前将样例数据顺序打乱，\n",
    "# 对于min_after_dequeue参数，假设是100\n",
    "min_after_dequeue = 100\n",
    "image_batch, label_batch = tf.train.shuffle_batch([images, labels],\n",
    "                                                  batch_size=batch_size, capacity=capacity,\n",
    "                                                  min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    for i in range(3):\n",
    "        xs, ys = sess.run([image_batch, label_batch])\n",
    "        print(xs, ys)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "'''打印的内容\n",
    "[[0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " ...\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]] [3 9 4 1 9 6 9 3 5 4]\n",
    "[[0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " ...\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]] [9 4 3 7 0 1 1 3 7 0]\n",
    "[[0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " ...\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]] [6 1 7 3 1 4 5 8 3 7]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
