{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多分类一个隐藏层的神经网络判断XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结构\n",
    "\n",
    "X  x  V  =>> L1  x   W ==>> L2\n",
    "\n",
    "\n",
    "## 数学形式\n",
    "\n",
    "```python\n",
    "X = np.array([[1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]])\n",
    "\n",
    "#标签\n",
    "Y = np.array([[0,1,1,0]])\n",
    "\n",
    "# 权重初始化，取值范围-1到1\n",
    "V = np.random.random((3,4))*2-1\n",
    "W = np.random.random((4,1))*2-1\n",
    "\n",
    "\n",
    "#更新权重函数\n",
    "def get_update():\n",
    "    global X,Y,W,V,lr\n",
    "    \n",
    "    ##　　　随机数的前向传递　　#############\n",
    "    \n",
    "    \n",
    "    \n",
    "    # L1：输入层传递给隐藏层的值；输入层3个节点，隐藏层4个节点\n",
    "    # L2：隐藏层传递到输出层的值；输出层1个节点\n",
    "    L1 = sigmoid(np.dot(X,V))\n",
    "    L2 = sigmoid(np.dot(L1,W))\n",
    "    \n",
    "    \n",
    "    ##　　　计算传递误差　　#############\n",
    "\n",
    "    # L2_delta：输出层的误差改变量\n",
    "    # L1_delta：隐藏层的误差改变量\n",
    "    L2_delta = (Y.T - L2)*dsigmoid(L2)\n",
    "    #print(\"误差改变量1\",L2_delta,type(L2_delta))\n",
    "    L1_delta = L2_delta.dot(W.T)*dsigmoid(L1)\n",
    "    #print(\"误差改变量2\",L1_delta,type(L1_delta))\n",
    "    # W_C：输出层对隐藏层的权重改变量\n",
    "    # V_C：隐藏层对输入层的权重改变量\n",
    "    \n",
    "    ##　　　将误差反向传递给超参数　　#############\n",
    "    W_C = lr * L1.T.dot(L2_delta)\n",
    "    V_C = lr * X.T.dot(L1_delta)\n",
    "\n",
    "    # 更新后的权重\n",
    "    W = W + W_C\n",
    "    V = V + V_C\n",
    "    \n",
    "##　　　主函数更新参数　　#############    \n",
    "def main():\n",
    "    for i in range(500000):\n",
    "        get_update()\n",
    "        #if i%500 == 0:\n",
    "        #    L1 = sigmoid(np.dot(X, V))\n",
    "        #    L2 = sigmoid(np.dot(L1, W))\n",
    "        #    print('进入了for循环当前误差',np.mean(np.abs(Y.T - L2)))\n",
    "    L1 = sigmoid(np.dot(X, V))\n",
    "    L2 = sigmoid(np.dot(L1, W))\n",
    "    print('最后逼近值：',L2,L1)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############\n",
      "最后逼近值： [[0.00156547]\n",
      " [0.99430442]\n",
      " [0.99426684]\n",
      " [0.00706866]] [[0.84860258 0.64193565 0.74924555 0.67726765]\n",
      " [0.02776108 0.98959193 0.99986602 0.98933684]\n",
      " [0.99994004 0.9910515  0.0310558  0.99122012]\n",
      " [0.98836511 0.99982977 0.98766228 0.9997997 ]]\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "lr = 0.11        #学习速率\n",
    "\n",
    "#输入数据分别:偏置值,x1,x2\n",
    "X = np.array([[1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]])\n",
    "\n",
    "#标签\n",
    "Y = np.array([[0,1,1,0]])\n",
    "\n",
    "# 权重初始化，取值范围-1到1\n",
    "V = np.random.random((3,4))*2-1\n",
    "W = np.random.random((4,1))*2-1\n",
    "#print('输入层连接隐藏层的权值V：',V)\n",
    "#print('隐藏层连接输出层的权值W：',W)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "#更新权重函数\n",
    "def get_update():\n",
    "    global X,Y,W,V,lr\n",
    "    # L1：输入层传递给隐藏层的值；输入层3个节点，隐藏层4个节点\n",
    "    # L2：隐藏层传递到输出层的值；输出层1个节点\n",
    "    L1 = sigmoid(np.dot(X,V))\n",
    "    L2 = sigmoid(np.dot(L1,W))\n",
    "\n",
    "    # L2_delta：输出层的误差改变量\n",
    "    # L1_delta：隐藏层的误差改变量\n",
    "    L2_delta = (Y.T - L2)*dsigmoid(L2)\n",
    "    #print(\"误差改变量1\",L2_delta,type(L2_delta))\n",
    "    L1_delta = L2_delta.dot(W.T)*dsigmoid(L1)\n",
    "    #print(\"误差改变量2\",L1_delta,type(L1_delta))\n",
    "    # W_C：输出层对隐藏层的权重改变量\n",
    "    # V_C：隐藏层对输入层的权重改变量\n",
    "    W_C = lr * L1.T.dot(L2_delta)\n",
    "    V_C = lr * X.T.dot(L1_delta)\n",
    "\n",
    "    # 更新后的权重\n",
    "    W = W + W_C\n",
    "    V = V + V_C\n",
    "\n",
    "def main():\n",
    "    for i in range(500000):\n",
    "        get_update()\n",
    "        #if i%500 == 0:\n",
    "        #    L1 = sigmoid(np.dot(X, V))\n",
    "        #    L2 = sigmoid(np.dot(L1, W))\n",
    "        #    print('进入了for循环当前误差',np.mean(np.abs(Y.T - L2)))\n",
    "    L1 = sigmoid(np.dot(X, V))\n",
    "    L2 = sigmoid(np.dot(L1, W))\n",
    "    print('最后逼近值：',L2,L1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"#############\")\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层神经网络一个输出（回归）\n",
    "[相关解读](https://blog.csdn.net/weixin_40432828/article/details/82192709)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from numpy import *\n",
    " \n",
    " \n",
    "######## 数据集 ########\n",
    " \n",
    "p_s = [[1,1,2],[1,2,3],[2,1,6],[5,2,5],[8,3,4],[7,7,4],[7,7,7],[13,8,3],[6,10,11],[13,0,17],[14,7,12]]              # 用来训练的数据集 x\n",
    "t_s = [[2],[6],[12],[50],[96],[196],[343],[312],[660],[0],[1176]]   # 用来训练的数据集 y\n",
    " \n",
    "p_t = [[6,9,1017],[2,3,4],[5,9,10]]      # 用来测试的数据集 x_test    \n",
    "t_t = [[54918],[24],[450]]               # 用来测试的数据集 对应的实际结果 y_test                                                                        \n",
    " \n",
    "######## 超参数设定 ########\n",
    " \n",
    "n_epoch = 20000             # 训练次数\n",
    " \n",
    "HNum = 2;                   # 各层隐藏层节点数\n",
    " \n",
    "HCNum = 2;                  # 隐藏层层数\n",
    " \n",
    "AFKind = 3;                 # 激励函数种类\n",
    "emax = 0.01;                # 最大允许均方差根\n",
    "LearnRate = 0.01;           # 学习率\n",
    " \n",
    "######## 中间变量设定 ########\n",
    "TNum = 7;                   # 特征层节点数 (特征数)\n",
    " \n",
    "SNum = len(p_s);            # 样本数\n",
    " \n",
    "INum = len(p_s[0]);         # 输入层节点数（每组数据的维度）\n",
    "ONum = len(t_s[0]);         # 输出层节点数（结果的维度）\n",
    "StudyTime = 0;              # 学习次数\n",
    "KtoOne = 0.0;               # 归一化系数\n",
    "e = 0.0;                    # 均方差跟\n",
    " \n",
    "######################################################### 主要矩阵设定 ######################################################\n",
    " \n",
    "I = zeros(INum);\n",
    " \n",
    "Ti = zeros(TNum);\n",
    "To = zeros(TNum);\n",
    " \n",
    "Hi = zeros((HCNum,HNum));\n",
    "Ho = zeros((HCNum,HNum));\n",
    " \n",
    "Oi = zeros(ONum);\n",
    "Oo = zeros(ONum);\n",
    " \n",
    "Teacher = zeros(ONum);\n",
    " \n",
    "u = 0.2*ones((TNum,HNum))                  # 初始化 权值矩阵u\n",
    "w = 0.2*ones(((HCNum-1,HNum,HNum)))        # 初始化 权值矩阵w\n",
    "v = 0.2*ones((HNum,ONum))                  # 初始化 权值矩阵v\n",
    " \n",
    "dw = zeros((HCNum-1,HNum,HNum))\n",
    " \n",
    "Hb = zeros((HCNum,HNum));\n",
    "Ob = zeros(ONum);\n",
    " \n",
    "He = zeros((HCNum,HNum));\n",
    "Oe = zeros(ONum);\n",
    " \n",
    "p_s = array(p_s)\n",
    "t_s = array(t_s)\n",
    "p_t = array(p_t)\n",
    " \n",
    "################################# 时间参数 #########################################\n",
    " \n",
    "time_start = 0.0\n",
    "time_gyuyihua = 0.0\n",
    "time_nnff = 0.0\n",
    "time_nnbp = 0.0\n",
    "time_begin = 0.0\n",
    " \n",
    "time_start2 = 0.0\n",
    " \n",
    "time_nnff1 = 0.0\n",
    "time_nnff2 = 0.0\n",
    "time_nnbp_v = 0.0\n",
    "time_nnbp_w = 0.0\n",
    "time_nnbp_u = 0.0\n",
    "time_nnbp_b = 0.0\n",
    " \n",
    " \n",
    " \n",
    "######################################################### 方法 #######################################################\n",
    " \n",
    "def Calcu_KtoOne(p,t):                         # 确定归一化系数\n",
    "\tp_max = p.max();\n",
    "\tt_max = t.max();\n",
    "\treturn max(p_max,t_max);\n",
    "\t\n",
    "def trait(p):                                  # 特征化\n",
    "\tt = zeros((p.shape[0],TNum));\n",
    "\tfor i in range(0,p.shape[0],1):\n",
    "\t\tt[i,0] = p[i,0]*p[i,1]*p[i,2]\n",
    "\t\tt[i,1] = p[i,0]*p[i,1]\n",
    "\t\tt[i,2] = p[i,0]*p[i,2]\n",
    "\t\tt[i,3] = p[i,1]*p[i,2]\n",
    "\t\tt[i,4] = p[i,0]\n",
    "\t\tt[i,5] = p[i,1]\n",
    "\t\tt[i,6] = p[i,2]\n",
    "\t\n",
    "\treturn t\n",
    "\t\n",
    "def AF(p,kind):   # 激励函数\n",
    "\tt = []\n",
    "\tif kind == 1:   # sigmoid\n",
    "\t\tpass\n",
    "\telif kind == 2:   # tanh\n",
    "\t\tpass\n",
    "\telif kind == 3:    # ReLU\n",
    " \n",
    "\t\treturn where(p<0,0,p)\n",
    "\telse:\n",
    "\t\tpass\n",
    " \n",
    " \n",
    "\t\t\n",
    "def dAF(p,kind):   # 激励函数导数\n",
    "\tt = []\n",
    "\tif kind == 1:   # sigmoid\n",
    "\t\tpass\n",
    "\telif kind == 2:   # tanh\n",
    "\t\tpass\n",
    "\telif kind == 3:    # ReLU\n",
    "\t\t\n",
    "\t\treturn where(p<0,0,1) \n",
    "\telse:\n",
    "\t\tpass\n",
    " \n",
    "\t\t\n",
    "\t\t\n",
    "def nnff(p,t):\n",
    "\tpass\n",
    "\t\n",
    "def nnbp(p,t):\n",
    "\tpass\n",
    "\t\n",
    " \n",
    "def train(p,t):                                # 训练\n",
    "\t\n",
    "\tglobal e\n",
    "\tglobal v\n",
    "\tglobal w\n",
    "\tglobal dw\n",
    "\tglobal u\t\n",
    "\tglobal I \n",
    "\tglobal Ti \n",
    "\tglobal To \n",
    "\tglobal Hi \n",
    "\tglobal Ho \n",
    "\tglobal Oi \n",
    "\tglobal Oo \n",
    "\tglobal Teacher \n",
    "\tglobal Hb \n",
    "\tglobal Ob \n",
    "\tglobal He \n",
    "\tglobal Oe\n",
    "\tglobal StudyTime\n",
    "\tglobal KtoOne\n",
    "\t\n",
    "\tglobal time_start\n",
    "\tglobal time_gyuyihua\n",
    "\tglobal time_nnff\n",
    "\tglobal time_nnbp\t\n",
    "\tglobal time_start2\n",
    "\tglobal time_nnff1\n",
    "\tglobal time_nnff2\n",
    "\tglobal time_nnbp_v\n",
    "\tglobal time_nnbp_w\n",
    "\tglobal time_nnbp_u\n",
    "\tglobal time_nnbp_b\n",
    "\t\n",
    "\t\n",
    "\ttime_start = time.clock()\n",
    "\t\n",
    "\t\n",
    "\te = 0.0\n",
    "\tp = trait(p)\n",
    "\t\t\n",
    "\tKtoOne = Calcu_KtoOne(p,t)\n",
    "\t\n",
    "\ttime_gyuyihua += (time.clock()-time_start)\n",
    "\t\n",
    "\ttime_start = time.clock()\n",
    "\t\t\n",
    "\tfor isamp in range(0,SNum,1):\n",
    "\t\tTo = p[isamp]/KtoOne\n",
    "\t\tTeacher = t[isamp]/KtoOne\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t################ 前向 nnff #############################\n",
    "\t\t\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t######## 计算各层隐藏层输入输出 Hi Ho ########\n",
    "\t\t\n",
    "\t\tfor k in range(0,HCNum,1):\n",
    "\t\t\tif k == 0:\n",
    "\t\t\t\tHi[k] = dot(To,u)\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\telse:\n",
    "\t\t\t\tHi[k] = dot(Ho[k-1],w[k-1])\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\ttime_nnff1 += (time.clock()-time_start2)\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t########   计算输出层输入输出 Oi Oo    ########\n",
    "\t\tOi = dot(Ho[HCNum-1],v)\n",
    "\t\tOo = AF(add(Oi,Ob),AFKind)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\ttime_nnff2 += (time.clock()-time_start2)\t\n",
    "\t\ttime_start2 = time.clock()\t\n",
    "\t\ttime_nnff += (time.clock()-time_start)\t\n",
    "\t\ttime_start = time.clock()\n",
    "\t\t\t\t\n",
    "\t\t################ 反向 nnbp #############################\n",
    "\t\t\n",
    "\t\t######## 反向更新 v ############\n",
    "\t\t\n",
    "\t\tOe = subtract(Teacher,Oo)\n",
    "\t\tOe = multiply(Oe,dAF(add(Oi,Ob),AFKind))\n",
    "\t\t\t\t\t\t\n",
    "\t\te += sum(multiply(Oe,Oe))\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#### v 梯度 ####\t\t\n",
    "\t\t\n",
    "\t\tdv = dot(array([Oe]),array([Ho[HCNum-1]])).transpose()\t\t\t  # v 的梯度\n",
    " \n",
    "\t\tv = add(v,dv*LearnRate)    # 更新 v\n",
    "\t\t\n",
    "\t\ttime_nnbp_v += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t######## 反向更新 w #############\n",
    "\t\tHe = zeros((HCNum,HNum))\n",
    "\t\n",
    "\t\tfor c in range(HCNum-2,-1,-1):\n",
    "\t\t\tif c == HCNum-2:\n",
    "\t\t\t\tHe[c+1] = dot(v,Oe)\n",
    "\t\t\t\tHe[c+1] = multiply(He[c+1],dAF(add(Hi[c+1],Hb[c+1]),AFKind))\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\t#dw[c] = dot(array([He[c+1]]),array([Ho[c]]).transpose())\n",
    "\t\t\t\tdw[c] = dot(array([Ho[c]]).transpose(),array([He[c+1]]))\n",
    "\t\t\t\t#dw[c] = dw[c].transpose()  #@@@@@@ 若结果不理想，可尝试用此条语句\n",
    "\t\t\t\t\n",
    "\t\t\t\tw[c] = add(w[c],LearnRate*dw[c])\n",
    "\t\t\t\t\n",
    "\t\t\n",
    "\t\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tHe[c+1] = dot(w[c+1],He[c+2])\n",
    "\t\t\t\tHe[c+1] = multiply(He[c+1],dAF(add(Hi[c+1],Hb[c+1]),AFKind))\n",
    "\t\t\t\t\n",
    "\t\t\t\tdw[c] = dot(array([Ho[c]]).transpose(),array([He[c+1]]))\t\n",
    "\t\t\t\t\n",
    "\t\t\t\tw[c] = add(w[c],LearnRate*dw[c])\n",
    " \n",
    "\t\ttime_nnbp_w += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t######## 反向更新 u #############\n",
    "\t\t\n",
    "\t\tHe[0] = dot(w[0],He[1])\n",
    "\t\tHe[0] = multiply(He[0],dAF(add(Hi[0],Hb[0]),AFKind))\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\tdu = dot(array([To]).transpose(),array([He[0]]))\n",
    "\t\t\t\t\n",
    "\t\tu = add(u,du)\n",
    "\t\t\n",
    "\t\ttime_nnbp_u += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\t\n",
    "\t\t######### 更新阈值 b ############\n",
    "\t\t\n",
    "\t\tOb = Ob + Oe*LearnRate\n",
    "\t\t\t\t\n",
    "\t\tHb = Hb + He*LearnRate\n",
    "\t\t\n",
    "\t\ttime_nnbp += (time.clock()-time_start)\n",
    "\t\n",
    "\t\ttime_start = time.clock()\n",
    "\t\t\n",
    "\t\ttime_nnbp_b += (time.clock()-time_start2)\n",
    "\t\n",
    "\t\ttime_start2 = time.clock()\n",
    "\t\n",
    "\te = sqrt(e)\n",
    " \n",
    "\t\n",
    "def predict(p):\n",
    "\t\t\t\t\n",
    "\tp = trait(p)\n",
    "\tp = p/KtoOne\n",
    "\tp_result = zeros((p.shape[0],1))\n",
    " \n",
    "\tfor isamp in range(0,p.shape[0],1):\n",
    "\t\tfor k in range(0,HCNum,1):\n",
    "\t\t\tif k == 0:\n",
    "\t\t\t\tHi[k] = dot(p[isamp],u)\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\telse:\n",
    "\t\t\t\tHi[k] = dot(Ho[k-1],w[k-1])\n",
    "\t\t\t\tHo[k] = AF(add(Hi[k],Hb[k]),AFKind)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t########   计算输出层输入输出 Oi Oo    ########\n",
    "\t\tOi = dot(Ho[HCNum-1],v)\n",
    "\t\tOo = AF(add(Oi,Ob),AFKind)\n",
    "\t\tOo = Oo*KtoOne\n",
    "\t\tp_result[isamp] = Oo\n",
    "\treturn p_result\n",
    " \n",
    "\t\n",
    "time_begin = time.clock()\n",
    " \n",
    "for i in range(1,n_epoch,1):\n",
    "\tif i%1000 == 0:\n",
    "\t\tprint('已训练 %d 千次 ,误差均方差 %f'%((i/1000),e))\n",
    "\ttrain(p_s,t_s)\n",
    "print('训练完成，共训练 %d 次，误差均方差 %f'%(i,e))\n",
    " \n",
    "print('共耗时: ',time.clock()-time_begin)\n",
    " \n",
    "print()\n",
    "\t\t\n",
    "result = predict(p_t)\n",
    " \n",
    "print('模型预测结果 : ')\n",
    "for i in result:\n",
    "\tprint('%.2f'%i)\n",
    "\t\t\n",
    "print('\\n实际结果 : ')\t\n",
    "for i in t_t:\n",
    "\tprint(i)\n",
    "\t\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
