{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras案例:ConvLstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liyuan3970/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/liyuan3970/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nseq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\\n        epochs=300, validation_split=0.05)\\n\\n# Testing the network on one movie\\n# feed it with the first 7 positions and then\\n# predict the new positions\\nwhich = 1004\\ntrack = noisy_movies[which][:7, ::, ::, ::]\\n\\nfor j in range(16):\\n    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\\n    new = new_pos[::, -1, ::, ::, ::]\\n    track = np.concatenate((track, new), axis=0)\\n\\n\\n# And then compare the predictions\\n# to the ground truth\\ntrack2 = noisy_movies[which][::, ::, ::, ::]\\nfor i in range(15):\\n    fig = plt.figure(figsize=(10, 5))\\n\\n    ax = fig.add_subplot(121)\\n\\n    if i >= 7:\\n        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\\n    else:\\n        ax.text(1, 3, 'Initial trajectory', fontsize=20)\\n\\n    toplot = track[i, ::, ::, 0]\\n\\n    plt.imshow(toplot)\\n    ax = fig.add_subplot(122)\\n    plt.text(1, 3, 'Ground truth', fontsize=20)\\n\\n    toplot = track2[i, ::, ::, 0]\\n    if i >= 2:\\n        toplot = shifted_movies[which][i - 1, ::, ::, 0]\\n\\n    plt.imshow(toplot)\\nplt.savefig('%i_animate.png' % (i + 1))\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This script demonstrates the use of a convolutional LSTM network.\n",
    "This network is used to predict the next frame of an artificially\n",
    "generated movie which contains moving squares.\n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "\n",
    "\n",
    "# Artificial data generation:\n",
    "# Generate movies with 3 to 7 moving squares inside.\n",
    "# The squares are of shape 1x1 or 2x2 pixels,\n",
    "# which move linearly over time.\n",
    "# For convenience we first create movies with bigger width and height (80x80)\n",
    "# and at the end we select a 40x40 window.\n",
    "\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# Train the network\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "\n",
    "\n",
    "'''\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        epochs=300, validation_split=0.05)\n",
    "\n",
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "\n",
    "\n",
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "plt.savefig('%i_animate.png' % (i + 1))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liyuan3970/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "950/950 [==============================] - 676s 712ms/step - loss: 0.2658 - val_loss: 0.4690\n",
      "Epoch 2/300\n",
      "950/950 [==============================] - 656s 690ms/step - loss: 0.0254 - val_loss: 0.3048\n",
      "Epoch 3/300\n",
      "950/950 [==============================] - 656s 691ms/step - loss: 0.0040 - val_loss: 0.3086\n",
      "Epoch 4/300\n",
      "950/950 [==============================] - 649s 683ms/step - loss: 0.0014 - val_loss: 0.3795\n",
      "Epoch 5/300\n",
      "950/950 [==============================] - 645s 679ms/step - loss: 7.5476e-04 - val_loss: 0.2430\n",
      "Epoch 6/300\n",
      "950/950 [==============================] - 646s 680ms/step - loss: 5.5030e-04 - val_loss: 0.0304\n",
      "Epoch 7/300\n",
      "950/950 [==============================] - 641s 674ms/step - loss: 4.5225e-04 - val_loss: 0.0018\n",
      "Epoch 8/300\n",
      "950/950 [==============================] - 638s 671ms/step - loss: 3.7637e-04 - val_loss: 6.0849e-04\n",
      "Epoch 9/300\n",
      "950/950 [==============================] - 638s 671ms/step - loss: 3.3329e-04 - val_loss: 3.7418e-04\n",
      "Epoch 10/300\n",
      "950/950 [==============================] - 637s 671ms/step - loss: 2.9529e-04 - val_loss: 2.9949e-04\n",
      "Epoch 11/300\n",
      "950/950 [==============================] - 640s 673ms/step - loss: 2.7021e-04 - val_loss: 2.6340e-04\n",
      "Epoch 12/300\n",
      "950/950 [==============================] - 640s 674ms/step - loss: 2.4561e-04 - val_loss: 2.4303e-04\n",
      "Epoch 13/300\n",
      "950/950 [==============================] - 634s 668ms/step - loss: 2.2905e-04 - val_loss: 2.2834e-04\n",
      "Epoch 14/300\n",
      "950/950 [==============================] - 642s 675ms/step - loss: 2.1395e-04 - val_loss: 2.2088e-04\n",
      "Epoch 15/300\n",
      "950/950 [==============================] - 636s 669ms/step - loss: 2.0256e-04 - val_loss: 2.0414e-04\n",
      "Epoch 16/300\n",
      "950/950 [==============================] - 634s 667ms/step - loss: 1.8580e-04 - val_loss: 2.1984e-04\n",
      "Epoch 17/300\n",
      "950/950 [==============================] - 631s 665ms/step - loss: 1.7760e-04 - val_loss: 1.7860e-04\n",
      "Epoch 18/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 1.6723e-04 - val_loss: 1.8001e-04\n",
      "Epoch 19/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 1.6173e-04 - val_loss: 1.7727e-04\n",
      "Epoch 20/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 1.5416e-04 - val_loss: 1.8206e-04\n",
      "Epoch 21/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 1.4684e-04 - val_loss: 1.5460e-04\n",
      "Epoch 22/300\n",
      "950/950 [==============================] - 633s 666ms/step - loss: 1.4229e-04 - val_loss: 1.7188e-04\n",
      "Epoch 23/300\n",
      "950/950 [==============================] - 632s 665ms/step - loss: 1.3679e-04 - val_loss: 1.5834e-04\n",
      "Epoch 24/300\n",
      "950/950 [==============================] - 629s 662ms/step - loss: 1.3099e-04 - val_loss: 1.5041e-04\n",
      "Epoch 25/300\n",
      "950/950 [==============================] - 629s 662ms/step - loss: 1.2705e-04 - val_loss: 1.4618e-04\n",
      "Epoch 26/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 1.2238e-04 - val_loss: 1.6910e-04\n",
      "Epoch 27/300\n",
      "950/950 [==============================] - 629s 662ms/step - loss: 1.1603e-04 - val_loss: 1.4394e-04\n",
      "Epoch 28/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 1.1489e-04 - val_loss: 1.4394e-04\n",
      "Epoch 29/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 1.0943e-04 - val_loss: 1.4643e-04\n",
      "Epoch 30/300\n",
      "950/950 [==============================] - 632s 665ms/step - loss: 1.0652e-04 - val_loss: 1.4175e-04\n",
      "Epoch 31/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 1.0274e-04 - val_loss: 1.4199e-04\n",
      "Epoch 32/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 1.0118e-04 - val_loss: 1.3681e-04\n",
      "Epoch 33/300\n",
      "950/950 [==============================] - 631s 665ms/step - loss: 9.7668e-05 - val_loss: 1.3302e-04\n",
      "Epoch 34/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 9.4909e-05 - val_loss: 1.2686e-04\n",
      "Epoch 35/300\n",
      "950/950 [==============================] - 633s 666ms/step - loss: 9.2858e-05 - val_loss: 1.2516e-04\n",
      "Epoch 36/300\n",
      "950/950 [==============================] - 632s 666ms/step - loss: 9.0529e-05 - val_loss: 1.2763e-04\n",
      "Epoch 37/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 8.9291e-05 - val_loss: 1.2302e-04\n",
      "Epoch 38/300\n",
      "950/950 [==============================] - 631s 664ms/step - loss: 8.6111e-05 - val_loss: 1.2655e-04\n",
      "Epoch 39/300\n",
      "950/950 [==============================] - 633s 666ms/step - loss: 8.2226e-05 - val_loss: 1.2174e-04\n",
      "Epoch 40/300\n",
      "950/950 [==============================] - 633s 667ms/step - loss: 8.2037e-05 - val_loss: 1.2834e-04\n",
      "Epoch 41/300\n",
      "950/950 [==============================] - 631s 665ms/step - loss: 7.9374e-05 - val_loss: 1.5762e-04\n",
      "Epoch 42/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 7.7729e-05 - val_loss: 1.1012e-04\n",
      "Epoch 43/300\n",
      "950/950 [==============================] - 630s 663ms/step - loss: 7.5058e-05 - val_loss: 1.1242e-04\n",
      "Epoch 44/300\n",
      "950/950 [==============================] - 628s 661ms/step - loss: 7.3812e-05 - val_loss: 1.2021e-04\n",
      "Epoch 45/300\n",
      "950/950 [==============================] - 635s 668ms/step - loss: 7.1714e-05 - val_loss: 1.2259e-04\n",
      "Epoch 46/300\n",
      "950/950 [==============================] - 634s 667ms/step - loss: 6.9381e-05 - val_loss: 1.1844e-04\n",
      "Epoch 47/300\n",
      "950/950 [==============================] - 643s 677ms/step - loss: 6.8503e-05 - val_loss: 1.1574e-04\n",
      "Epoch 48/300\n",
      "880/950 [==========================>...] - ETA: 46s - loss: 6.5711e-05"
     ]
    }
   ],
   "source": [
    "\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        epochs=300, validation_split=0.05)\n",
    "\n",
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "\n",
    "\n",
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "plt.savefig('%i_animate.png' % (i + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“DeepLearning”",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
