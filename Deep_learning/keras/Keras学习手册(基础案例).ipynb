{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层感知机\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "768/768 [==============================] - 0s 165us/step - loss: 3.2006 - accuracy: 0.5846\n",
      "Epoch 2/10\n",
      "768/768 [==============================] - 0s 57us/step - loss: 0.9588 - accuracy: 0.5729\n",
      "Epoch 3/10\n",
      "768/768 [==============================] - 0s 60us/step - loss: 0.7628 - accuracy: 0.6302\n",
      "Epoch 4/10\n",
      "768/768 [==============================] - 0s 57us/step - loss: 0.7198 - accuracy: 0.6536\n",
      "Epoch 5/10\n",
      "768/768 [==============================] - 0s 57us/step - loss: 0.6946 - accuracy: 0.6784\n",
      "Epoch 6/10\n",
      "768/768 [==============================] - 0s 56us/step - loss: 0.6678 - accuracy: 0.6862\n",
      "Epoch 7/10\n",
      "768/768 [==============================] - 0s 56us/step - loss: 0.6625 - accuracy: 0.6719\n",
      "Epoch 8/10\n",
      "768/768 [==============================] - 0s 58us/step - loss: 0.6476 - accuracy: 0.6862\n",
      "Epoch 9/10\n",
      "768/768 [==============================] - 0s 56us/step - loss: 0.6345 - accuracy: 0.7031\n",
      "Epoch 10/10\n",
      "768/768 [==============================] - 0s 55us/step - loss: 0.6445 - accuracy: 0.6745\n",
      "768/768 [==============================] - 0s 35us/step\n",
      "\n",
      "accuracy : 70.18%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# 二分类问题\n",
    "# 设定随机数种子\n",
    "np.random.seed(7)\n",
    "file = 'deeplearning-master/chapter03/'\n",
    "# 导入数据\n",
    "dataset = np.loadtxt(file + 'pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# 创建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x=x, y=Y, epochs=10, batch_size=10)\n",
    "\n",
    "# 评估模型\n",
    "scores = model.evaluate(x=x, y=Y)\n",
    "print('\\n%s : %.2f%%' % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.23%\n",
      "accuracy: 72.73%\n",
      "accuracy: 61.04%\n",
      "accuracy: 72.73%\n",
      "accuracy: 64.94%\n",
      "accuracy: 62.34%\n",
      "accuracy: 51.95%\n",
      "accuracy: 63.64%\n",
      "accuracy: 55.26%\n",
      "accuracy: 55.26%\n",
      "62.61% (+/- 6.70%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "file = 'deeplearning-master/chapter03/'\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt(file +'pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "cvscores = []\n",
    "for train, validation in kfold.split(x, Y):\n",
    "    # 创建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(x[train], Y[train], epochs=10, batch_size=10, verbose=0)\n",
    "\n",
    "    # 评估模型\n",
    "    scores = model.evaluate(x[validation], Y[validation], verbose=0)\n",
    "\n",
    "    # 输出评估结果\n",
    "    print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "# 输出均值和标准差\n",
    "print('%.2f%% (+/- %.2f%%)' % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动划分数据集为测试和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/10\n",
      "614/614 [==============================] - 0s 396us/step - loss: 3.6363 - accuracy: 0.5782 - val_loss: 1.2658 - val_accuracy: 0.5974\n",
      "Epoch 2/10\n",
      "614/614 [==============================] - 0s 80us/step - loss: 1.1059 - accuracy: 0.5472 - val_loss: 0.8410 - val_accuracy: 0.6234\n",
      "Epoch 3/10\n",
      "614/614 [==============================] - 0s 77us/step - loss: 0.8455 - accuracy: 0.6059 - val_loss: 0.7747 - val_accuracy: 0.6299\n",
      "Epoch 4/10\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.7927 - accuracy: 0.6482 - val_loss: 0.7140 - val_accuracy: 0.6104\n",
      "Epoch 5/10\n",
      "614/614 [==============================] - 0s 79us/step - loss: 0.7382 - accuracy: 0.6498 - val_loss: 0.6711 - val_accuracy: 0.6429\n",
      "Epoch 6/10\n",
      "614/614 [==============================] - 0s 84us/step - loss: 0.7405 - accuracy: 0.6384 - val_loss: 0.6531 - val_accuracy: 0.6299\n",
      "Epoch 7/10\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.7141 - accuracy: 0.6433 - val_loss: 0.6246 - val_accuracy: 0.7338\n",
      "Epoch 8/10\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.6911 - accuracy: 0.6319 - val_loss: 0.6774 - val_accuracy: 0.6688\n",
      "Epoch 9/10\n",
      "614/614 [==============================] - 0s 79us/step - loss: 0.6937 - accuracy: 0.6515 - val_loss: 0.6255 - val_accuracy: 0.6688\n",
      "Epoch 10/10\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.6844 - accuracy: 0.6482 - val_loss: 0.6232 - val_accuracy: 0.7013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f16f07b16d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "file = 'deeplearning-master/chapter03/'\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt(file+'pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# 分割数据集\n",
    "x_train, x_validation, Y_train, Y_validation = train_test_split(x, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# 构建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, Y_train, validation_data=(x_validation, Y_validation), epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多分类+K折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.00% (0.29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 构建模型函数\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean()*100, results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归问题(网格索索最佳参数+K折)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -22.86 (11.15) MSE\n",
      "Standardize: -12.65 (6.98) MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyuan3970/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/liyuan3970/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -23.936282 using {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-36.911271 (20.581943) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-23.936282 (16.188013) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-47.840865 (35.397575) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-30.762740 (13.868749) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-57.498930 (40.035697) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-51.492124 (45.805657) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-39.341064 (16.861257) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-35.687907 (19.236443) with: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-40.370533 (20.916212) with: {'batch_size': 5, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-58.869322 (65.388510) with: {'batch_size': 5, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-84.438131 (91.845757) with: {'batch_size': 5, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-62.262438 (55.997704) with: {'batch_size': 5, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-33.201868 (13.469587) with: {'batch_size': 5, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-33.399247 (17.378340) with: {'batch_size': 5, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-52.506343 (40.046827) with: {'batch_size': 5, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-30.714155 (14.461844) with: {'batch_size': 5, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-67.744587 (58.169480) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-43.819387 (18.746483) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-81.564441 (63.986808) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-69.160466 (58.233099) with: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-99.611230 (82.340022) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-64.846148 (43.263483) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-91.231913 (64.067863) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-75.607342 (56.271025) with: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-41.720758 (28.117922) with: {'batch_size': 20, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-32.523662 (14.632236) with: {'batch_size': 20, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-75.627095 (56.726126) with: {'batch_size': 20, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-31.784301 (19.989731) with: {'batch_size': 20, 'epochs': 200, 'init': 'glorot_uniform', 'optimizer': 'adam', 'units_list': [13, 6]}\n",
      "-64.909328 (53.117824) with: {'batch_size': 20, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [20]}\n",
      "-47.915441 (33.333419) with: {'batch_size': 20, 'epochs': 200, 'init': 'normal', 'optimizer': 'rmsprop', 'units_list': [13, 6]}\n",
      "-68.708099 (58.977540) with: {'batch_size': 20, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam', 'units_list': [20]}\n",
      "-41.868857 (26.252136) with: {'batch_size': 20, 'epochs': 200, 'init': 'normal', 'optimizer': 'adam', 'units_list': [13, 6]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# 导入数据\n",
    "dataset = datasets.load_boston()\n",
    "\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 构建模型函数\n",
    "def create_model(units_list=[13],optimizer='adam', init='normal'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "\n",
    "    # 构建第一个隐藏层和输入层\n",
    "    units = units_list[0]\n",
    "    model.add(Dense(units=units, activation='relu', input_dim=13, kernel_initializer=init))\n",
    "    # 构建更多隐藏层\n",
    "    for units in units_list[1:]:\n",
    "        model.add(Dense(units=units, activation='relu', kernel_initializer=init))\n",
    "\n",
    "    model.add(Dense(units=1, kernel_initializer=init))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
    "\n",
    "\n",
    "# 设置算法评估基准\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print('Baseline: %.2f (%.2f) MSE' % (results.mean(), results.std()))\n",
    "\n",
    "# 数据正态化，改进算法\n",
    "steps = []\n",
    "steps.append(('standardize', StandardScaler()))\n",
    "steps.append(('mlp', model))\n",
    "pipeline = Pipeline(steps)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, x, Y, cv=kfold)\n",
    "print('Standardize: %.2f (%.2f) MSE' % (results.mean(), results.std()))\n",
    "\n",
    "# 调参选择最优模型\n",
    "param_grid = {}\n",
    "param_grid['units_list'] = [[20], [13, 6]]\n",
    "param_grid['optimizer'] = ['rmsprop', 'adam']\n",
    "param_grid['init'] = ['glorot_uniform', 'normal']\n",
    "param_grid['epochs'] = [100, 200]\n",
    "param_grid['batch_size'] = [5, 20]\n",
    "\n",
    "# 调参\n",
    "scaler = StandardScaler()\n",
    "scaler_x = scaler.fit_transform(x)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "results = grid.fit(scaler_x, Y)\n",
    "\n",
    "# 输出结果\n",
    "print('Best: %f using %s' % (results.best_score_, results.best_params_))\n",
    "means = results.cv_results_['mean_test_score']\n",
    "stds = results.cv_results_['std_test_score']\n",
    "params = results.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print('%f (%f) with: %r' % (mean, std, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
