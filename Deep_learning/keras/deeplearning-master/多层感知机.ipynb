{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 6.9844 - accuracy: 0.6224\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 179us/step - loss: 1.5784 - accuracy: 0.5456\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.7926 - accuracy: 0.4062\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 205us/step - loss: 0.7601 - accuracy: 0.4792\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.7311 - accuracy: 0.6523\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.7168 - accuracy: 0.6615\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.7023 - accuracy: 0.6562\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.6924 - accuracy: 0.6562\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.6734 - accuracy: 0.6628\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6689 - accuracy: 0.6549\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.6610 - accuracy: 0.6589\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.6494 - accuracy: 0.6680\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.6485 - accuracy: 0.6641\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 174us/step - loss: 0.6360 - accuracy: 0.6719\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6333 - accuracy: 0.6719\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6301 - accuracy: 0.6784\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.6393 - accuracy: 0.6680\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.6252 - accuracy: 0.6823\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.6234 - accuracy: 0.6810\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.6210 - accuracy: 0.6836\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.6212 - accuracy: 0.6862\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6163 - accuracy: 0.6836\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.6135 - accuracy: 0.6849\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.6295 - accuracy: 0.6758\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.6194 - accuracy: 0.6810\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6136 - accuracy: 0.6862\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 184us/step - loss: 0.6188 - accuracy: 0.6823\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.6169 - accuracy: 0.6836\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.6122 - accuracy: 0.6849\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.6123 - accuracy: 0.6836\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 198us/step - loss: 0.6170 - accuracy: 0.6862\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.6126 - accuracy: 0.6875\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.6130 - accuracy: 0.6927\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6140 - accuracy: 0.6875\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.6118 - accuracy: 0.6914\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.6070 - accuracy: 0.6927\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.6072 - accuracy: 0.6953\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.6098 - accuracy: 0.6888\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.6136 - accuracy: 0.6862\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6091 - accuracy: 0.6927\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.6096 - accuracy: 0.6836\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.6210 - accuracy: 0.6810\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.6231 - accuracy: 0.6758\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.6074 - accuracy: 0.6888\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.6042 - accuracy: 0.6927\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6060 - accuracy: 0.6979\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.6059 - accuracy: 0.6888\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.6044 - accuracy: 0.6979\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.6043 - accuracy: 0.6953\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.6088 - accuracy: 0.6953\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.6062 - accuracy: 0.6875\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.6052 - accuracy: 0.6953\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.6079 - accuracy: 0.6901\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.6022 - accuracy: 0.6992\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.6034 - accuracy: 0.6979\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.6031 - accuracy: 0.7031\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.6051 - accuracy: 0.6927\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 197us/step - loss: 0.6052 - accuracy: 0.6901\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5978 - accuracy: 0.7044\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.6019 - accuracy: 0.6966\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6056 - accuracy: 0.6888\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5991 - accuracy: 0.6966\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 184us/step - loss: 0.5990 - accuracy: 0.6914\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5980 - accuracy: 0.7005\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5989 - accuracy: 0.7057\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.5968 - accuracy: 0.7031\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.5967 - accuracy: 0.6940\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.6018 - accuracy: 0.6992\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 195us/step - loss: 0.5988 - accuracy: 0.6979\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.6064 - accuracy: 0.6875\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.5974 - accuracy: 0.6979\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5999 - accuracy: 0.6901\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.6034 - accuracy: 0.6927\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.6003 - accuracy: 0.6940\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.5933 - accuracy: 0.7018\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.6004 - accuracy: 0.6992\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.5943 - accuracy: 0.7018\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5920 - accuracy: 0.7018\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.5984 - accuracy: 0.6966\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5943 - accuracy: 0.7070\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.5931 - accuracy: 0.7109\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5959 - accuracy: 0.6966\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5937 - accuracy: 0.7018\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 184us/step - loss: 0.5969 - accuracy: 0.7005\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5903 - accuracy: 0.7044\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 174us/step - loss: 0.5973 - accuracy: 0.6966\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5927 - accuracy: 0.6992\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.5911 - accuracy: 0.7096\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5923 - accuracy: 0.7031\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5940 - accuracy: 0.6979\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 184us/step - loss: 0.5971 - accuracy: 0.7018\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5973 - accuracy: 0.6992\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5917 - accuracy: 0.7096\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5925 - accuracy: 0.7018\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.5975 - accuracy: 0.6953\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 172us/step - loss: 0.5911 - accuracy: 0.7148\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.5884 - accuracy: 0.7096\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5914 - accuracy: 0.7057\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5947 - accuracy: 0.7031\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5936 - accuracy: 0.7018\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5895 - accuracy: 0.7070\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.5947 - accuracy: 0.7070\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.5868 - accuracy: 0.7109\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.5857 - accuracy: 0.7148\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.5922 - accuracy: 0.7096\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.5894 - accuracy: 0.7044\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.5957 - accuracy: 0.6992\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5917 - accuracy: 0.7109\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.5912 - accuracy: 0.7135\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.5873 - accuracy: 0.7044\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5919 - accuracy: 0.7005\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5843 - accuracy: 0.7109\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5898 - accuracy: 0.7018\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 231us/step - loss: 0.5978 - accuracy: 0.7044\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.5874 - accuracy: 0.7044\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 184us/step - loss: 0.5895 - accuracy: 0.7031\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5868 - accuracy: 0.7070\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 197us/step - loss: 0.5879 - accuracy: 0.7018\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.5934 - accuracy: 0.7031\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.5852 - accuracy: 0.7070\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5888 - accuracy: 0.7044\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.5858 - accuracy: 0.7135\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5908 - accuracy: 0.6979\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 198us/step - loss: 0.5893 - accuracy: 0.7018\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.5855 - accuracy: 0.7122\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 198us/step - loss: 0.5852 - accuracy: 0.7122\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5830 - accuracy: 0.7161\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.5921 - accuracy: 0.7005\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.5851 - accuracy: 0.7018\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.5844 - accuracy: 0.7161\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5865 - accuracy: 0.7096\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5849 - accuracy: 0.7083\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5851 - accuracy: 0.7018\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5875 - accuracy: 0.7044\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5859 - accuracy: 0.7096\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.5817 - accuracy: 0.7109\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.5842 - accuracy: 0.7135\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5867 - accuracy: 0.6992\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 237us/step - loss: 0.5828 - accuracy: 0.7096\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 226us/step - loss: 0.5823 - accuracy: 0.7214\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5832 - accuracy: 0.7096\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.5853 - accuracy: 0.7070\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5823 - accuracy: 0.7083\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.5847 - accuracy: 0.7031\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.5846 - accuracy: 0.7135\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.5857 - accuracy: 0.7122\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 202us/step - loss: 0.5929 - accuracy: 0.7083\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5837 - accuracy: 0.7057\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.5844 - accuracy: 0.7057\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 197us/step - loss: 0.5823 - accuracy: 0.7109\n",
      "768/768 [==============================] - 0s 101us/step\n"
     ]
    }
   ],
   "source": [
    "#### from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# 设定随机数种子\n",
    "#np.random.seed(7)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt('chapter03/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# 创建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x=x, y=Y, epochs=150, batch_size=10)\n",
    "\n",
    "# 评估模型\n",
    "scores = model.evaluate(x=x, y=Y)\n",
    "#print('\\n%s : %.2f%%' % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估深度学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 0s 789us/step - loss: 4.0203 - accuracy: 0.5798 - val_loss: 1.2265 - val_accuracy: 0.6429\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 247us/step - loss: 1.0719 - accuracy: 0.5358 - val_loss: 0.7700 - val_accuracy: 0.6753\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.7927 - accuracy: 0.6075 - val_loss: 0.8761 - val_accuracy: 0.6234\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 269us/step - loss: 0.7526 - accuracy: 0.6482 - val_loss: 0.6951 - val_accuracy: 0.6818\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.7380 - accuracy: 0.6498 - val_loss: 0.7222 - val_accuracy: 0.6104\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.7036 - accuracy: 0.6596 - val_loss: 0.7660 - val_accuracy: 0.6623\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.6893 - accuracy: 0.6726 - val_loss: 0.6743 - val_accuracy: 0.6883\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.6610 - accuracy: 0.6759 - val_loss: 0.6692 - val_accuracy: 0.6688\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.6600 - accuracy: 0.6857 - val_loss: 0.6705 - val_accuracy: 0.6429\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.6378 - accuracy: 0.6889 - val_loss: 0.6652 - val_accuracy: 0.6558\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.6229 - accuracy: 0.6987 - val_loss: 0.6910 - val_accuracy: 0.6494\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.6189 - accuracy: 0.7101 - val_loss: 0.6633 - val_accuracy: 0.6623\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.6148 - accuracy: 0.6922 - val_loss: 0.6680 - val_accuracy: 0.6429\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.6344 - accuracy: 0.6889 - val_loss: 0.7118 - val_accuracy: 0.5779\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.6248 - accuracy: 0.6987 - val_loss: 0.6620 - val_accuracy: 0.6688\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.6066 - accuracy: 0.6954 - val_loss: 0.6570 - val_accuracy: 0.6623\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.6148 - accuracy: 0.6954 - val_loss: 0.6391 - val_accuracy: 0.6883\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.5986 - accuracy: 0.6987 - val_loss: 0.6360 - val_accuracy: 0.6883\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5914 - accuracy: 0.7036 - val_loss: 0.6552 - val_accuracy: 0.6688\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5951 - accuracy: 0.7068 - val_loss: 0.6646 - val_accuracy: 0.6364\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.5792 - accuracy: 0.7068 - val_loss: 0.7300 - val_accuracy: 0.6623\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.5793 - accuracy: 0.7134 - val_loss: 0.7030 - val_accuracy: 0.5844\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5782 - accuracy: 0.7166 - val_loss: 0.6496 - val_accuracy: 0.6623\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.5864 - accuracy: 0.7003 - val_loss: 0.6532 - val_accuracy: 0.6429\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.5817 - accuracy: 0.7215 - val_loss: 0.6728 - val_accuracy: 0.5714\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.5988 - accuracy: 0.7003 - val_loss: 0.6327 - val_accuracy: 0.6623\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5956 - accuracy: 0.7052 - val_loss: 0.6436 - val_accuracy: 0.6818\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5796 - accuracy: 0.7117 - val_loss: 0.6493 - val_accuracy: 0.6623\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5767 - accuracy: 0.7085 - val_loss: 0.6205 - val_accuracy: 0.7013\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.5542 - accuracy: 0.7362 - val_loss: 0.6924 - val_accuracy: 0.6364\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5619 - accuracy: 0.7199 - val_loss: 0.6194 - val_accuracy: 0.6623\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5615 - accuracy: 0.7215 - val_loss: 0.6106 - val_accuracy: 0.7013\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5626 - accuracy: 0.7199 - val_loss: 0.6170 - val_accuracy: 0.7013\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.5536 - accuracy: 0.7280 - val_loss: 0.6640 - val_accuracy: 0.6494\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5571 - accuracy: 0.7215 - val_loss: 0.6811 - val_accuracy: 0.6818\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5778 - accuracy: 0.7052 - val_loss: 0.6038 - val_accuracy: 0.7078\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5513 - accuracy: 0.7150 - val_loss: 0.5906 - val_accuracy: 0.7013\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.5530 - accuracy: 0.7362 - val_loss: 0.6439 - val_accuracy: 0.6753\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5587 - accuracy: 0.7264 - val_loss: 0.5990 - val_accuracy: 0.7143\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5459 - accuracy: 0.7231 - val_loss: 0.6136 - val_accuracy: 0.6883\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5456 - accuracy: 0.7362 - val_loss: 0.5967 - val_accuracy: 0.6883\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.5388 - accuracy: 0.7313 - val_loss: 0.6058 - val_accuracy: 0.7143\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.5465 - accuracy: 0.7248 - val_loss: 0.5893 - val_accuracy: 0.7078\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5451 - accuracy: 0.7296 - val_loss: 0.5935 - val_accuracy: 0.6948\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.5538 - accuracy: 0.7329 - val_loss: 0.6038 - val_accuracy: 0.7078\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5639 - accuracy: 0.7248 - val_loss: 0.5921 - val_accuracy: 0.7143\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5525 - accuracy: 0.7101 - val_loss: 0.6918 - val_accuracy: 0.5909\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5429 - accuracy: 0.7345 - val_loss: 0.5949 - val_accuracy: 0.7273\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.5349 - accuracy: 0.7329 - val_loss: 0.5981 - val_accuracy: 0.7273\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5527 - accuracy: 0.7345 - val_loss: 0.6068 - val_accuracy: 0.7013\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5325 - accuracy: 0.7264 - val_loss: 0.6697 - val_accuracy: 0.7013\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5279 - accuracy: 0.7378 - val_loss: 0.6048 - val_accuracy: 0.7078\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.5371 - accuracy: 0.7427 - val_loss: 0.5680 - val_accuracy: 0.7208\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.5272 - accuracy: 0.7362 - val_loss: 0.5846 - val_accuracy: 0.7013\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5290 - accuracy: 0.7362 - val_loss: 0.5776 - val_accuracy: 0.7143\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5312 - accuracy: 0.7264 - val_loss: 0.5882 - val_accuracy: 0.7143\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5512 - accuracy: 0.7150 - val_loss: 0.6101 - val_accuracy: 0.6623\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 210us/step - loss: 0.5426 - accuracy: 0.7199 - val_loss: 0.5575 - val_accuracy: 0.7403\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5296 - accuracy: 0.7394 - val_loss: 0.5772 - val_accuracy: 0.7013\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5241 - accuracy: 0.7345 - val_loss: 0.5534 - val_accuracy: 0.7792\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5252 - accuracy: 0.7459 - val_loss: 0.5548 - val_accuracy: 0.7403\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5128 - accuracy: 0.7394 - val_loss: 0.5626 - val_accuracy: 0.7273\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5087 - accuracy: 0.7573 - val_loss: 0.5754 - val_accuracy: 0.7078\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.5307 - accuracy: 0.7492 - val_loss: 0.5663 - val_accuracy: 0.7143\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5044 - accuracy: 0.7492 - val_loss: 0.5538 - val_accuracy: 0.7532\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.5190 - accuracy: 0.7427 - val_loss: 0.6081 - val_accuracy: 0.7078\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.5139 - accuracy: 0.7410 - val_loss: 0.5599 - val_accuracy: 0.7208\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.5313 - accuracy: 0.7199 - val_loss: 0.6201 - val_accuracy: 0.6753\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5222 - accuracy: 0.7394 - val_loss: 0.5437 - val_accuracy: 0.7468\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5204 - accuracy: 0.7394 - val_loss: 0.5612 - val_accuracy: 0.7338\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5209 - accuracy: 0.7524 - val_loss: 0.5655 - val_accuracy: 0.7273\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5192 - accuracy: 0.7476 - val_loss: 0.6079 - val_accuracy: 0.6883\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.5293 - accuracy: 0.7378 - val_loss: 0.5567 - val_accuracy: 0.7273\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5025 - accuracy: 0.7378 - val_loss: 0.5646 - val_accuracy: 0.7338\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5137 - accuracy: 0.7508 - val_loss: 0.5547 - val_accuracy: 0.7403\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.5092 - accuracy: 0.7459 - val_loss: 0.5491 - val_accuracy: 0.7727\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.5054 - accuracy: 0.7427 - val_loss: 0.5592 - val_accuracy: 0.7078\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5024 - accuracy: 0.7443 - val_loss: 0.5382 - val_accuracy: 0.7792\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.5229 - accuracy: 0.7427 - val_loss: 0.5464 - val_accuracy: 0.7338\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 207us/step - loss: 0.5078 - accuracy: 0.7476 - val_loss: 0.6017 - val_accuracy: 0.7143\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5115 - accuracy: 0.7378 - val_loss: 0.5659 - val_accuracy: 0.7208\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5090 - accuracy: 0.7427 - val_loss: 0.6359 - val_accuracy: 0.6623\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.5075 - accuracy: 0.7459 - val_loss: 0.5581 - val_accuracy: 0.7208\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.4988 - accuracy: 0.7443 - val_loss: 0.5502 - val_accuracy: 0.7273\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.5158 - accuracy: 0.7280 - val_loss: 0.6105 - val_accuracy: 0.6688\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.5034 - accuracy: 0.7557 - val_loss: 0.5589 - val_accuracy: 0.7273\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.4927 - accuracy: 0.7638 - val_loss: 0.5746 - val_accuracy: 0.7143\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5041 - accuracy: 0.7590 - val_loss: 0.5427 - val_accuracy: 0.7338\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5029 - accuracy: 0.7476 - val_loss: 0.5934 - val_accuracy: 0.6623\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5124 - accuracy: 0.7476 - val_loss: 0.5384 - val_accuracy: 0.7468\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.4971 - accuracy: 0.7638 - val_loss: 0.5437 - val_accuracy: 0.7403\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.4982 - accuracy: 0.7329 - val_loss: 0.5329 - val_accuracy: 0.7403\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.5009 - accuracy: 0.7443 - val_loss: 0.5597 - val_accuracy: 0.7143\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5093 - accuracy: 0.7736 - val_loss: 0.5924 - val_accuracy: 0.7208\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.5288 - accuracy: 0.7378 - val_loss: 0.6204 - val_accuracy: 0.7078\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.5027 - accuracy: 0.7329 - val_loss: 0.6129 - val_accuracy: 0.6818\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 198us/step - loss: 0.5104 - accuracy: 0.7345 - val_loss: 0.5379 - val_accuracy: 0.7273\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5005 - accuracy: 0.7443 - val_loss: 0.6295 - val_accuracy: 0.7013\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.5105 - accuracy: 0.7459 - val_loss: 0.6040 - val_accuracy: 0.6623\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5094 - accuracy: 0.7541 - val_loss: 0.5566 - val_accuracy: 0.7662\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 207us/step - loss: 0.5198 - accuracy: 0.7362 - val_loss: 0.5733 - val_accuracy: 0.7143\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 205us/step - loss: 0.5015 - accuracy: 0.7655 - val_loss: 0.5594 - val_accuracy: 0.7208\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.4838 - accuracy: 0.7541 - val_loss: 0.5382 - val_accuracy: 0.7273\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.4938 - accuracy: 0.7671 - val_loss: 0.5606 - val_accuracy: 0.7403\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.4965 - accuracy: 0.7541 - val_loss: 0.5592 - val_accuracy: 0.7273\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.4885 - accuracy: 0.7638 - val_loss: 0.5347 - val_accuracy: 0.7792\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.4964 - accuracy: 0.7541 - val_loss: 0.5681 - val_accuracy: 0.6948\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.4885 - accuracy: 0.7638 - val_loss: 0.5332 - val_accuracy: 0.7338\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.4925 - accuracy: 0.7638 - val_loss: 0.5300 - val_accuracy: 0.7727\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.5157 - accuracy: 0.7459 - val_loss: 0.5230 - val_accuracy: 0.7597\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.4934 - accuracy: 0.7704 - val_loss: 0.5537 - val_accuracy: 0.7792\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.5084 - accuracy: 0.7557 - val_loss: 0.5336 - val_accuracy: 0.7338\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 205us/step - loss: 0.4785 - accuracy: 0.7687 - val_loss: 0.5783 - val_accuracy: 0.7468\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5006 - accuracy: 0.7590 - val_loss: 0.5756 - val_accuracy: 0.7532\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.4930 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7727\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.4946 - accuracy: 0.7687 - val_loss: 0.5825 - val_accuracy: 0.7078\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.4786 - accuracy: 0.7736 - val_loss: 0.6216 - val_accuracy: 0.6948\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.4793 - accuracy: 0.7769 - val_loss: 0.5474 - val_accuracy: 0.7208\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.4859 - accuracy: 0.7704 - val_loss: 0.5388 - val_accuracy: 0.7208\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.4708 - accuracy: 0.7769 - val_loss: 0.5424 - val_accuracy: 0.7143\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.4821 - accuracy: 0.7785 - val_loss: 0.5494 - val_accuracy: 0.7273\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 214us/step - loss: 0.4754 - accuracy: 0.7785 - val_loss: 0.5781 - val_accuracy: 0.7013\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.4749 - accuracy: 0.7769 - val_loss: 0.5470 - val_accuracy: 0.7468\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.4812 - accuracy: 0.7720 - val_loss: 0.5525 - val_accuracy: 0.7143\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.4796 - accuracy: 0.7834 - val_loss: 0.5618 - val_accuracy: 0.7468\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.4885 - accuracy: 0.7622 - val_loss: 0.5495 - val_accuracy: 0.7338\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.4801 - accuracy: 0.7801 - val_loss: 0.5519 - val_accuracy: 0.7338\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.4802 - accuracy: 0.7590 - val_loss: 0.5482 - val_accuracy: 0.7013\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.4932 - accuracy: 0.7655 - val_loss: 0.5336 - val_accuracy: 0.7403\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.4959 - accuracy: 0.7557 - val_loss: 0.5936 - val_accuracy: 0.6623\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.4734 - accuracy: 0.7932 - val_loss: 0.5535 - val_accuracy: 0.7597\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.4818 - accuracy: 0.7704 - val_loss: 0.5474 - val_accuracy: 0.7338\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.5786 - val_accuracy: 0.6948\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.4851 - accuracy: 0.7671 - val_loss: 0.5395 - val_accuracy: 0.7403\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.4965 - accuracy: 0.7638 - val_loss: 0.5873 - val_accuracy: 0.7403\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.4776 - accuracy: 0.7590 - val_loss: 0.5372 - val_accuracy: 0.7273\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.4754 - accuracy: 0.7785 - val_loss: 0.5263 - val_accuracy: 0.7727\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.4764 - accuracy: 0.7704 - val_loss: 0.5339 - val_accuracy: 0.7338\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.4704 - accuracy: 0.7720 - val_loss: 0.5363 - val_accuracy: 0.7532\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.4760 - accuracy: 0.7720 - val_loss: 0.5658 - val_accuracy: 0.7532\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.4752 - accuracy: 0.7834 - val_loss: 0.5829 - val_accuracy: 0.7208\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.4759 - accuracy: 0.7769 - val_loss: 0.5679 - val_accuracy: 0.7338\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.4731 - accuracy: 0.7638 - val_loss: 0.5483 - val_accuracy: 0.7662\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.4788 - accuracy: 0.7687 - val_loss: 0.5194 - val_accuracy: 0.7727\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.4791 - accuracy: 0.7720 - val_loss: 0.5387 - val_accuracy: 0.7338\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.4647 - accuracy: 0.7850 - val_loss: 0.5914 - val_accuracy: 0.7273\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.4694 - accuracy: 0.7818 - val_loss: 0.5561 - val_accuracy: 0.7468\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.4740 - accuracy: 0.7818 - val_loss: 0.5210 - val_accuracy: 0.7338\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.4802 - accuracy: 0.7866 - val_loss: 0.5874 - val_accuracy: 0.7338\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.4656 - accuracy: 0.7801 - val_loss: 0.5593 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7efe28e22400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 设定随机数种子\n",
    "np.random.seed(7)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt('chapter05/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# 创建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型并自动评估模型\n",
    "model.fit(x=x, y=Y, epochs=150, batch_size=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手动评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 0s 617us/step - loss: 3.6570 - accuracy: 0.5782 - val_loss: 1.2681 - val_accuracy: 0.5974\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 241us/step - loss: 1.1068 - accuracy: 0.5472 - val_loss: 0.8425 - val_accuracy: 0.6169\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.8460 - accuracy: 0.6107 - val_loss: 0.7751 - val_accuracy: 0.6299\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.7908 - accuracy: 0.6466 - val_loss: 0.7119 - val_accuracy: 0.6104\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.7382 - accuracy: 0.6498 - val_loss: 0.6705 - val_accuracy: 0.6429\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.7410 - accuracy: 0.6368 - val_loss: 0.6521 - val_accuracy: 0.6364\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.7141 - accuracy: 0.6466 - val_loss: 0.6252 - val_accuracy: 0.7403\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.6913 - accuracy: 0.6303 - val_loss: 0.6814 - val_accuracy: 0.6753\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.6923 - accuracy: 0.6531 - val_loss: 0.6223 - val_accuracy: 0.6818\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.6838 - accuracy: 0.6450 - val_loss: 0.6255 - val_accuracy: 0.7013\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.6720 - accuracy: 0.6596 - val_loss: 0.5737 - val_accuracy: 0.7078\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.6844 - accuracy: 0.6547 - val_loss: 0.6077 - val_accuracy: 0.7013\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.6482 - accuracy: 0.6694 - val_loss: 0.6038 - val_accuracy: 0.6753\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.6470 - accuracy: 0.6954 - val_loss: 0.6248 - val_accuracy: 0.6818\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.6385 - accuracy: 0.6840 - val_loss: 0.5645 - val_accuracy: 0.7403\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.6238 - accuracy: 0.7052 - val_loss: 0.5542 - val_accuracy: 0.7338\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.6251 - accuracy: 0.6938 - val_loss: 0.5617 - val_accuracy: 0.7468\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 196us/step - loss: 0.6159 - accuracy: 0.6840 - val_loss: 0.5698 - val_accuracy: 0.7078\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.6242 - accuracy: 0.6840 - val_loss: 0.5787 - val_accuracy: 0.6948\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.6148 - accuracy: 0.6873 - val_loss: 0.5819 - val_accuracy: 0.7078\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.6075 - accuracy: 0.6954 - val_loss: 0.5731 - val_accuracy: 0.7403\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.6051 - accuracy: 0.6808 - val_loss: 0.5408 - val_accuracy: 0.7597\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.6016 - accuracy: 0.6906 - val_loss: 0.5578 - val_accuracy: 0.7468\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.6116 - accuracy: 0.7003 - val_loss: 0.6140 - val_accuracy: 0.6948\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5822 - accuracy: 0.6987 - val_loss: 0.5538 - val_accuracy: 0.7403\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.5877 - accuracy: 0.6954 - val_loss: 0.5492 - val_accuracy: 0.7338\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 201us/step - loss: 0.5951 - accuracy: 0.6824 - val_loss: 0.5540 - val_accuracy: 0.7468\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5836 - accuracy: 0.7134 - val_loss: 0.5536 - val_accuracy: 0.7597\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5734 - accuracy: 0.7117 - val_loss: 0.5497 - val_accuracy: 0.7468\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.5842 - accuracy: 0.6873 - val_loss: 0.5950 - val_accuracy: 0.6948\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5803 - accuracy: 0.7117 - val_loss: 0.6229 - val_accuracy: 0.6818\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5795 - accuracy: 0.6938 - val_loss: 0.6002 - val_accuracy: 0.6948\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5529 - accuracy: 0.7134 - val_loss: 0.5542 - val_accuracy: 0.7468\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.5541 - accuracy: 0.7068 - val_loss: 0.5897 - val_accuracy: 0.6688\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5716 - accuracy: 0.7020 - val_loss: 0.5609 - val_accuracy: 0.7208\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5760 - accuracy: 0.6938 - val_loss: 0.5613 - val_accuracy: 0.7403\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5472 - accuracy: 0.7199 - val_loss: 0.5363 - val_accuracy: 0.7922\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.5511 - accuracy: 0.7003 - val_loss: 0.5474 - val_accuracy: 0.7468\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.5595 - accuracy: 0.7134 - val_loss: 0.6058 - val_accuracy: 0.6883\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5662 - accuracy: 0.7020 - val_loss: 0.5460 - val_accuracy: 0.7792\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5613 - accuracy: 0.7117 - val_loss: 0.5420 - val_accuracy: 0.7468\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.5469 - accuracy: 0.7101 - val_loss: 0.5776 - val_accuracy: 0.7078\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5558 - accuracy: 0.7248 - val_loss: 0.5552 - val_accuracy: 0.7403\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5615 - accuracy: 0.7264 - val_loss: 0.5445 - val_accuracy: 0.7727\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.5438 - accuracy: 0.7134 - val_loss: 0.5375 - val_accuracy: 0.7987\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.5353 - accuracy: 0.7231 - val_loss: 0.5336 - val_accuracy: 0.7857\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5378 - accuracy: 0.7150 - val_loss: 0.5755 - val_accuracy: 0.7208\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.5555 - accuracy: 0.7182 - val_loss: 0.5884 - val_accuracy: 0.7013\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5365 - accuracy: 0.7296 - val_loss: 0.5296 - val_accuracy: 0.7857\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 200us/step - loss: 0.5251 - accuracy: 0.7248 - val_loss: 0.5539 - val_accuracy: 0.7532\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5302 - accuracy: 0.7394 - val_loss: 0.5622 - val_accuracy: 0.7338\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5321 - accuracy: 0.7166 - val_loss: 0.5457 - val_accuracy: 0.7727\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.5673 - accuracy: 0.6938 - val_loss: 0.5330 - val_accuracy: 0.7922\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.5271 - accuracy: 0.7296 - val_loss: 0.5365 - val_accuracy: 0.7792\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 225us/step - loss: 0.5432 - accuracy: 0.6987 - val_loss: 0.5388 - val_accuracy: 0.7792\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.5186 - accuracy: 0.7313 - val_loss: 0.5625 - val_accuracy: 0.7338\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5223 - accuracy: 0.7590 - val_loss: 0.6261 - val_accuracy: 0.6818\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 209us/step - loss: 0.5235 - accuracy: 0.7476 - val_loss: 0.5261 - val_accuracy: 0.7987\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5239 - accuracy: 0.7362 - val_loss: 0.5381 - val_accuracy: 0.7727\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.5250 - accuracy: 0.7182 - val_loss: 0.5361 - val_accuracy: 0.7727\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5422 - accuracy: 0.7296 - val_loss: 0.5295 - val_accuracy: 0.7922\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.5365 - accuracy: 0.7150 - val_loss: 0.5244 - val_accuracy: 0.7662\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.5303 - accuracy: 0.7313 - val_loss: 0.5326 - val_accuracy: 0.7857\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 204us/step - loss: 0.5343 - accuracy: 0.7345 - val_loss: 0.5780 - val_accuracy: 0.7338\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5209 - accuracy: 0.7248 - val_loss: 0.5458 - val_accuracy: 0.7662\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 195us/step - loss: 0.5160 - accuracy: 0.7443 - val_loss: 0.5184 - val_accuracy: 0.7792\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 252us/step - loss: 0.5209 - accuracy: 0.7345 - val_loss: 0.5318 - val_accuracy: 0.7662\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.5258 - accuracy: 0.7296 - val_loss: 0.5269 - val_accuracy: 0.8052\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.5183 - accuracy: 0.7606 - val_loss: 0.5468 - val_accuracy: 0.7597\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.5234 - accuracy: 0.7378 - val_loss: 0.5305 - val_accuracy: 0.7792\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.5137 - accuracy: 0.7459 - val_loss: 0.5388 - val_accuracy: 0.7857\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.5219 - accuracy: 0.7410 - val_loss: 0.5327 - val_accuracy: 0.7727\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.5411 - accuracy: 0.7117 - val_loss: 0.5635 - val_accuracy: 0.7403\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5141 - accuracy: 0.7508 - val_loss: 0.5594 - val_accuracy: 0.7532\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 221us/step - loss: 0.5316 - accuracy: 0.7329 - val_loss: 0.5343 - val_accuracy: 0.7792\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 210us/step - loss: 0.5158 - accuracy: 0.7378 - val_loss: 0.5291 - val_accuracy: 0.7987\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 219us/step - loss: 0.5146 - accuracy: 0.7557 - val_loss: 0.5281 - val_accuracy: 0.7597\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 224us/step - loss: 0.5295 - accuracy: 0.7296 - val_loss: 0.5446 - val_accuracy: 0.7727\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 212us/step - loss: 0.5248 - accuracy: 0.7231 - val_loss: 0.5672 - val_accuracy: 0.7273\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 217us/step - loss: 0.5194 - accuracy: 0.7345 - val_loss: 0.5191 - val_accuracy: 0.7727\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5158 - accuracy: 0.7345 - val_loss: 0.5655 - val_accuracy: 0.7143\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5305 - accuracy: 0.7410 - val_loss: 0.5711 - val_accuracy: 0.7143\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.5278 - accuracy: 0.7394 - val_loss: 0.5259 - val_accuracy: 0.7792\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.5181 - accuracy: 0.7410 - val_loss: 0.5410 - val_accuracy: 0.7468\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 215us/step - loss: 0.5144 - accuracy: 0.7541 - val_loss: 0.5464 - val_accuracy: 0.7338\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.5148 - accuracy: 0.7362 - val_loss: 0.5654 - val_accuracy: 0.7403\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 277us/step - loss: 0.5072 - accuracy: 0.7492 - val_loss: 0.5315 - val_accuracy: 0.7662\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5336 - accuracy: 0.7280 - val_loss: 0.5683 - val_accuracy: 0.7078\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.5006 - accuracy: 0.7410 - val_loss: 0.5602 - val_accuracy: 0.7273\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.5042 - accuracy: 0.7508 - val_loss: 0.5256 - val_accuracy: 0.7857\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.5076 - accuracy: 0.7443 - val_loss: 0.5517 - val_accuracy: 0.7403\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 201us/step - loss: 0.5078 - accuracy: 0.7378 - val_loss: 0.5271 - val_accuracy: 0.7857\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 273us/step - loss: 0.5044 - accuracy: 0.7443 - val_loss: 0.5314 - val_accuracy: 0.7857\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.5056 - accuracy: 0.7492 - val_loss: 0.5469 - val_accuracy: 0.7403\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 341us/step - loss: 0.5099 - accuracy: 0.7524 - val_loss: 0.5400 - val_accuracy: 0.7727\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.4970 - accuracy: 0.7573 - val_loss: 0.5225 - val_accuracy: 0.8052\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.5258 - accuracy: 0.7231 - val_loss: 0.5765 - val_accuracy: 0.6948\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 230us/step - loss: 0.5114 - accuracy: 0.7264 - val_loss: 0.5511 - val_accuracy: 0.7468\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.5045 - accuracy: 0.7524 - val_loss: 0.5328 - val_accuracy: 0.7727\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.4996 - accuracy: 0.7345 - val_loss: 0.5365 - val_accuracy: 0.7597\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 245us/step - loss: 0.5121 - accuracy: 0.7313 - val_loss: 0.5536 - val_accuracy: 0.7338\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 239us/step - loss: 0.4965 - accuracy: 0.7541 - val_loss: 0.5333 - val_accuracy: 0.7597\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.4903 - accuracy: 0.7476 - val_loss: 0.5556 - val_accuracy: 0.7273\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 250us/step - loss: 0.5153 - accuracy: 0.7280 - val_loss: 0.5247 - val_accuracy: 0.8182\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.5103 - accuracy: 0.7443 - val_loss: 0.5200 - val_accuracy: 0.8052\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.5026 - accuracy: 0.7410 - val_loss: 0.5286 - val_accuracy: 0.7532\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5069 - accuracy: 0.7378 - val_loss: 0.5541 - val_accuracy: 0.7338\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 222us/step - loss: 0.4956 - accuracy: 0.7508 - val_loss: 0.5335 - val_accuracy: 0.7987\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.5030 - accuracy: 0.7492 - val_loss: 0.5215 - val_accuracy: 0.7922\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 248us/step - loss: 0.5001 - accuracy: 0.7492 - val_loss: 0.6848 - val_accuracy: 0.6623\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.5146 - accuracy: 0.7410 - val_loss: 0.5471 - val_accuracy: 0.7987\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.5106 - accuracy: 0.7508 - val_loss: 0.5400 - val_accuracy: 0.7727\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 261us/step - loss: 0.4927 - accuracy: 0.7443 - val_loss: 0.5228 - val_accuracy: 0.8117\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 226us/step - loss: 0.4928 - accuracy: 0.7378 - val_loss: 0.5420 - val_accuracy: 0.7532\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.5025 - accuracy: 0.7345 - val_loss: 0.5777 - val_accuracy: 0.7273\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 198us/step - loss: 0.5198 - accuracy: 0.7345 - val_loss: 0.5462 - val_accuracy: 0.7857\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 229us/step - loss: 0.5018 - accuracy: 0.7459 - val_loss: 0.6095 - val_accuracy: 0.6753\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 260us/step - loss: 0.4947 - accuracy: 0.7443 - val_loss: 0.5363 - val_accuracy: 0.7662\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.4903 - accuracy: 0.7378 - val_loss: 0.5451 - val_accuracy: 0.7727\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 314us/step - loss: 0.4975 - accuracy: 0.7590 - val_loss: 0.5202 - val_accuracy: 0.8117\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.4897 - accuracy: 0.7427 - val_loss: 0.5403 - val_accuracy: 0.7532\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 231us/step - loss: 0.4920 - accuracy: 0.7410 - val_loss: 0.5305 - val_accuracy: 0.7597\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.5146 - accuracy: 0.7329 - val_loss: 0.5276 - val_accuracy: 0.7987\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.4985 - accuracy: 0.7443 - val_loss: 0.5279 - val_accuracy: 0.7987\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 216us/step - loss: 0.4800 - accuracy: 0.7443 - val_loss: 0.5259 - val_accuracy: 0.7792\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 290us/step - loss: 0.4968 - accuracy: 0.7459 - val_loss: 0.5175 - val_accuracy: 0.8052\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 256us/step - loss: 0.4886 - accuracy: 0.7671 - val_loss: 0.5271 - val_accuracy: 0.7857\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.4930 - accuracy: 0.7590 - val_loss: 0.5429 - val_accuracy: 0.7727\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 208us/step - loss: 0.4942 - accuracy: 0.7459 - val_loss: 0.5298 - val_accuracy: 0.7922\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 253us/step - loss: 0.4947 - accuracy: 0.7524 - val_loss: 0.5320 - val_accuracy: 0.7727\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 244us/step - loss: 0.4822 - accuracy: 0.7606 - val_loss: 0.5264 - val_accuracy: 0.7987\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.4937 - accuracy: 0.7362 - val_loss: 0.5396 - val_accuracy: 0.7662\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 246us/step - loss: 0.5031 - accuracy: 0.7459 - val_loss: 0.5469 - val_accuracy: 0.7727\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 242us/step - loss: 0.4843 - accuracy: 0.7638 - val_loss: 0.5372 - val_accuracy: 0.8182\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.4872 - accuracy: 0.7508 - val_loss: 0.5527 - val_accuracy: 0.7662\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 254us/step - loss: 0.4952 - accuracy: 0.7443 - val_loss: 0.5582 - val_accuracy: 0.7727\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 233us/step - loss: 0.5087 - accuracy: 0.7524 - val_loss: 0.5374 - val_accuracy: 0.8117\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 243us/step - loss: 0.4931 - accuracy: 0.7443 - val_loss: 0.5866 - val_accuracy: 0.7013\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 240us/step - loss: 0.4814 - accuracy: 0.7508 - val_loss: 0.5297 - val_accuracy: 0.8182\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 234us/step - loss: 0.4810 - accuracy: 0.7362 - val_loss: 0.5359 - val_accuracy: 0.8052\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 235us/step - loss: 0.4774 - accuracy: 0.7638 - val_loss: 0.5766 - val_accuracy: 0.7273\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 236us/step - loss: 0.5029 - accuracy: 0.7313 - val_loss: 0.5327 - val_accuracy: 0.7727\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 241us/step - loss: 0.4883 - accuracy: 0.7541 - val_loss: 0.5449 - val_accuracy: 0.7857\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 238us/step - loss: 0.4943 - accuracy: 0.7508 - val_loss: 0.5368 - val_accuracy: 0.7987\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 228us/step - loss: 0.4830 - accuracy: 0.7590 - val_loss: 0.5728 - val_accuracy: 0.7403\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 263us/step - loss: 0.4944 - accuracy: 0.7410 - val_loss: 0.5849 - val_accuracy: 0.7078\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 237us/step - loss: 0.4861 - accuracy: 0.7671 - val_loss: 0.5610 - val_accuracy: 0.7403\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.4775 - accuracy: 0.7573 - val_loss: 0.5270 - val_accuracy: 0.8052\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.4918 - accuracy: 0.7508 - val_loss: 0.5755 - val_accuracy: 0.7013\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 232us/step - loss: 0.4887 - accuracy: 0.7492 - val_loss: 0.5495 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7efe1b9c9d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt('chapter05/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# 分割数据集\n",
    "x_train, x_validation, Y_train, Y_validation = train_test_split(x, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# 构建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, Y_train, validation_data=(x_validation, Y_validation), epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K折训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.22%\n",
      "accuracy: 75.32%\n",
      "accuracy: 63.64%\n",
      "accuracy: 81.82%\n",
      "accuracy: 79.22%\n",
      "accuracy: 83.12%\n",
      "accuracy: 64.94%\n",
      "accuracy: 66.23%\n",
      "accuracy: 68.42%\n",
      "accuracy: 68.42%\n",
      "73.03% (+/- 7.09%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt('chapter05/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "cvscores = []\n",
    "for train, validation in kfold.split(x, Y):\n",
    "    # 创建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(x[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "    # 评估模型\n",
    "    scores = model.evaluate(x[validation], Y[validation], verbose=0)\n",
    "\n",
    "    # 输出评估结果\n",
    "    print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "# 输出均值和标准差\n",
    "print('%.2f%% (+/- %.2f%%)' % (np.mean(cvscores), np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在SK-Learn 中使用Kears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7355604887008667\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# 构建模型\n",
    "def create_model():\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(units=8, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt('chapter05/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "#创建模型 for scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# 10折交叉验证\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数调节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyuan3970/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=12, kernel_initializer=init, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(units=8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(units=1, kernel_initializer=init, activation='sigmoid'))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "# 设定随机数种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 导入数据\n",
    "dataset = np.loadtxt('chapter05/pima-indians-diabetes.csv', delimiter=',')\n",
    "# 分割输入x和输出Y\n",
    "x = dataset[:, 0 : 8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "#创建模型 for scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# 构建需要调参的参数\n",
    "param_grid = {}\n",
    "param_grid['optimizer'] = ['rmsprop', 'adam']\n",
    "param_grid['init'] = ['glorot_uniform', 'normal', 'uniform']\n",
    "param_grid['epochs'] = [50, 100, 150, 200]\n",
    "param_grid['batch_size'] = [5, 10, 20]\n",
    "\n",
    "# 调参\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "results = grid.fit(x, Y)\n",
    "\n",
    "# 输出结果\n",
    "print('Best: %f using %s' % (results.best_score_, results.best_params_))\n",
    "means = results.cv_results_['mean_test_score']\n",
    "stds = results.cv_results_['std_test_score']\n",
    "params = results.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print('%f (%f) with: %r' % (mean, std, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.33% (0.10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 导入数据\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "x = dataset.data\n",
    "Y = dataset.target\n",
    "\n",
    "# 设定随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 构建模型函数\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
    "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean()*100, results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier0\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import read_csv\n",
    "\n",
    "# 导入数据并将分类转化为数字\n",
    "dataset = read_csv('chapter09/bank.csv', delimiter=';')\n",
    "dataset['job'] = dataset['job'].replace(to_replace=['admin.', 'unknown', 'unemployed', 'management',\n",
    "                                                    'housemaid', 'entrepreneur', 'student', 'blue-collar',\n",
    "                                                    'self-employed', 'retired', 'technician', 'services'],\n",
    "                                        value=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "dataset['marital'] = dataset['marital'].replace(to_replace=['married', 'single', 'divorced'], value=[0, 1, 2])\n",
    "dataset['education'] = dataset['education'].replace(to_replace=['unknown', 'secondary', 'primary', 'tertiary'],\n",
    "                                                    value=[0, 2, 1, 3])\n",
    "dataset['default'] = dataset['default'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "dataset['housing'] = dataset['housing'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "dataset['loan'] = dataset['loan'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "dataset['contact'] = dataset['contact'].replace(to_replace=['cellular', 'unknown', 'telephone'], value=[0, 1, 2])\n",
    "dataset['poutcome'] = dataset['poutcome'].replace(to_replace=['unknown', 'other', 'success', 'failure'],\n",
    "                                                  value=[0, 1, 2, 3])\n",
    "dataset['month'] = dataset['month'].replace(to_replace=['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
    "                                                        'jul', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
    "                                            value=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "dataset['y'] = dataset['y'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "\n",
    "# 分离输入输出\n",
    "array = dataset.values\n",
    "x = array[:, 0:16]\n",
    "Y = array[:, 16]\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# 构建模型函数\n",
    "def create_model(units_list=[16], optimizer='adam', init='normal'):\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "\n",
    "    # 构建第一个隐藏层和输入层\n",
    "    units = units_list[0]\n",
    "    model.add(Dense(units=units, activation='relu', input_dim=16, kernel_initializer=init))\n",
    "    # 构建更多隐藏层\n",
    "    for units in units_list[1:]:\n",
    "        model.add(Dense(units=units, activation='relu', kernel_initializer=init))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x, Y, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean() * 100, results.std()))\n",
    "\n",
    "new_x = StandardScaler().fit_transform(x)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, new_x, Y, cv=kfold)\n",
    "print('Accuracy: %.2f%% (%.2f)' % (results.mean() * 100, results.std()))\n",
    "\n",
    "# 调参选择最优模型\n",
    "param_grid = {}\n",
    "param_grid['units_list'] = [[16], [30], [16, 8], [30, 8]]\n",
    "# 调参\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "results = grid.fit(new_x, Y)\n",
    "\n",
    "# 输出结果\n",
    "print('Best: %f using %s' % (results.best_score_, results.best_params_))\n",
    "means = results.cv_results_['mean_test_score']\n",
    "stds = results.cv_results_['std_test_score']\n",
    "params = results.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print('%f (%f) with: %r' % (mean, std, param))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
