{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型编译的方法(快速开始--Sequential顺序模型指引)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 二分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 均方误差回归问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# 自定义评估标准函数\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于具有 2 个类的单输入模型（二进制分类）：\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于具有 10 个类的单输入模型（多分类分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# 将标签转换为分类的 one-hot 编码\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 样例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知机的softmax多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 40)\n",
      "(1000, 10)\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 2.4546 - accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 2.3758 - accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 2.3307 - accuracy: 0.0910\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 9us/step - loss: 2.3137 - accuracy: 0.1010\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 2.3090 - accuracy: 0.1150\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 2.3108 - accuracy: 0.0990\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 2.3134 - accuracy: 0.0890\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 2.2964 - accuracy: 0.1060\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 8us/step - loss: 2.3010 - accuracy: 0.1100\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 9us/step - loss: 2.3007 - accuracy: 0.1180\n",
      "100/100 [==============================] - 0s 452us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "# 1000是数据数量，40是特征数\n",
    "x_train = np.random.random((1000, 40))\n",
    "# num_classes 是输出的分类数\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_test = np.random.random((100, 40))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) 是一个具有 64 个隐藏神经元的全连接层。\n",
    "# 在第一层必须指定所期望的输入数据尺寸：\n",
    "# 在这里，input_dim是一个 40 维的向量。表示输入的数据\n",
    "# \n",
    "model.add(Dense(128, activation='relu', input_dim=40))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# epochs是训练次数，batch是一次训练喂给模型的数据尺寸\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知器的二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.7330 - accuracy: 0.4850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 9us/step - loss: 0.7058 - accuracy: 0.5210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.7009 - accuracy: 0.5190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.7034 - accuracy: 0.4900\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 7us/step - loss: 0.7027 - accuracy: 0.5050\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.6959 - accuracy: 0.5300\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.6971 - accuracy: 0.5180\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.6901 - accuracy: 0.5420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 0.6985 - accuracy: 0.4980\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.6966 - accuracy: 0.5290\n",
      "100/100 [==============================] - 0s 513us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG神经网络的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0407 11:19:57.017666 139742941493056 deprecation_wrapper.py:119] From /home/liyuan3970/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.3753\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.3136\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.3136\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2673\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2901\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2906\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2916\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2931\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.2832\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2712\n",
      "20/20 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# 输入: 3 通道 100x100 像素图像 -> (100, 100, 3) 张量。\n",
    "# 使用 32 个大小为 3x3 的卷积滤波器。\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于LSTM的序列分类(不懂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 823us/step - loss: 0.0268 - accuracy: 0.9840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 7.9238e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 1.1935e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 1.5232e-07 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 3.0906e-08 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 1.9324e-08 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 9.6077e-09 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 671us/step - loss: 1.0360e-08 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 724us/step - loss: 6.0400e-09 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 699us/step - loss: 5.6594e-09 - accuracy: 1.0000\n",
      "100/100 [==============================] - 0s 671us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import keras\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(1, size=(1000, 1)), num_classes=1)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(1, size=(100, 1)), num_classes=1)\n",
    "max_features = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于1D卷积的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "seq_length = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于栈式LSTM的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(32, return_sequences=True))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(32))  # 返回维度为 32 的单个向量\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stateful式的LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "# 请注意，我们必须提供完整的 batch_input_shape，因为网络是有状态的。\n",
    "# 第 k 批数据的第 i 个样本是第 k-1 批数据的第 i 个样本的后续。\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=5, shuffle=False,\n",
    "          validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
