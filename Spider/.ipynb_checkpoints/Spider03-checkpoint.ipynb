{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取腾讯二级子页面的数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "class TencentSpider(object):\n",
    "  def __init__(self):\n",
    "    self.headers = {'User-Agent':'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; InfoPath.3)'}\n",
    "\n",
    "  # 获取工作职责和工作要求(发请求并解析二级页面)\n",
    "  def get_job_duty(self,url):\n",
    "    # 获取二级页面响应内容\n",
    "    res = requests.get(url,headers=self.headers)\n",
    "    res.encoding = 'utf-8'\n",
    "    html = res.text\n",
    "    # 正则提取职责和要求\n",
    "    p = re.compile('<tr class=\"c\">.*?<ul class=\"squareli\">(.*?)</ul>',re.S)\n",
    "    job_info = p.findall(html)\n",
    "    # job_info : ['<li>1.职责一</li>\\n<li>','']\n",
    "    duty = job_info[0].strip().replace('<li>','').replace('</li>','')\n",
    "    requirement = job_info[1].strip().replace('<li>','').replace('</li','')\n",
    "    # 返回处理好的职责和要求字符串\n",
    "    return duty,requirement\n",
    "\n",
    "\n",
    "\n",
    "  # 获取一级子界面职位信息\n",
    "  def get_job_info(self,url,params):\n",
    "    res = requests.get(url,params=params,headers=self.headers)\n",
    "    res.encoding = 'utf-8'\n",
    "    html = res.text\n",
    "    # 交给解析函数去做解析\n",
    "    self.parse_job_info(html)\n",
    "\n",
    "  # 解析职位信息\n",
    "  def parse_job_info(self,html):\n",
    "    p = re.compile('<td class=\"l square\">.*?href=\"(.*?)\">(.*?)</a>.*?<td>(.*?)</td>.*?<td>(.*?)</td>.*?<td>(.*?)</td>.*?<td>(.*?)</td>',re.S)\n",
    "    job_info_list = p.findall(html)\n",
    "    # job_info_list:[('链接','名称','类别','人数','地点','时间'),(),(),(),()]\n",
    "    for job in job_info_list:\n",
    "      job_link = 'https://hr.tencent.com/'+job[0]\n",
    "      job_name = job[1]\n",
    "      job_type = job[2]\n",
    "      job_number = job[3]\n",
    "      job_address = job[4]\n",
    "      job_time = job[5]\n",
    "      job_duty,job_requirement = self.get_job_duty(job_link)\n",
    "\n",
    "\n",
    "      d = {\n",
    "        '职位链接:' : job_link,\n",
    "        '职位名称:' : job_name,\n",
    "        '职位类别:' : job_type,\n",
    "        '招聘人数:' : job_number,\n",
    "        '招聘地点:' : job_address,\n",
    "        '发布时间:' : job_time,\n",
    "        '工作职责:' : job_duty,\n",
    "        '工作要求:' : job_requirement\n",
    "      }\n",
    "      print(d)\n",
    "      print('*' * 30)\n",
    "\n",
    "  # 数据处理\n",
    "  def write_page(self):\n",
    "    pass\n",
    "\n",
    "  # 主函数\n",
    "  def work_on(self):\n",
    "    job = input('请输入职位方向:')\n",
    "\n",
    "    for pn in range(0,2001,10):\n",
    "      url = 'https://hr.tencent.com/position.php?'\n",
    "      params = {\n",
    "          'keywords': job,\n",
    "          'start' : str(pn)\n",
    "        }\n",
    "      self.get_job_info(url,params)\n",
    "      time.sleep(2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  start = time.time()\n",
    "  spider = TencentSpider()\n",
    "  spider.work_on()\n",
    "  end = time.time()\n",
    "  print('执行时间:%.2f' % (end-start))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 拼接url信息\n",
    "import requests\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0'}\n",
    "url = 'http://www.baidu.com/s?'\n",
    "\n",
    "key = input('请输入要搜索的内容:')\n",
    "params = {\n",
    "    'wd' : key,\n",
    "    'pn' : '10'\n",
    "  }\n",
    "# 三步走,自动对params编码,后和基准url进行拼接\n",
    "res = requests.get(url,params=params,headers=headers)\n",
    "res.encoding = 'utf-8'\n",
    "html = res.text\n",
    "\n",
    "print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置代理\n",
    "import requests\n",
    "\n",
    "# 测试网址,能显示出口IP\n",
    "url = 'http://httpbin.org/get'\n",
    "headers = {'User-Agent' : 'Mozilla/5.0'}\n",
    "# 定义一个代理\n",
    "proxies = {\n",
    "    'http':'http://159.224.13.29:61366',\n",
    "    'https':'https://159.224.13.29:61366'\n",
    "  }\n",
    "# proxies = {\n",
    "#     'http':'http://309435365:szayclhp@116.255.191.105:16816'\n",
    "# }\n",
    "\n",
    "# 发请求\n",
    "res = requests.get(url,\n",
    "                   headers=headers,\n",
    "                   proxies=proxies)\n",
    "res.encoding = 'utf-8'\n",
    "html = res.text\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##设置代理　和密码\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "\n",
    "class NoteSpider(object):\n",
    "  def __init__(self):\n",
    "    self.headers = {'User-Agent':'Mozilla/5.0'}\n",
    "    # 使用普通代理\n",
    "    self.proxies = {\n",
    "          'http':'http://111.177.183.54:9999',\n",
    "          'https':'https://111.177.183.54:9999'\n",
    "    }\n",
    "    # web客户端验证参数\n",
    "    self.auth = ('tarenacode','code_2013')\n",
    "\n",
    "  # 获取解析页面\n",
    "  def get_page(self,url):\n",
    "    # 获取页面\n",
    "    res = requests.get(url,\n",
    "                       headers=self.headers,\n",
    "                       auth=self.auth,\n",
    "                       proxies=self.proxies)\n",
    "    res.encoding = 'utf-8'\n",
    "    html = res.text\n",
    "    # 解析页面\n",
    "    p = re.compile('<a href=\"(.*?)/.*?</a>',re.S)\n",
    "    r_list = p.findall(html)\n",
    "    print(r_list)\n",
    "    # r_list : ['..','AIDCode','','']\n",
    "    self.write_page(r_list)\n",
    "\n",
    "  # 保存数据\n",
    "  def write_page(self,r_list):\n",
    "    with open('Note.csv','w') as f:\n",
    "      # 创建写入对象\n",
    "      writer = csv.writer(f)\n",
    "      for r in r_list:\n",
    "        if r != '..':\n",
    "          writer.writerow([r])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  spider = NoteSpider()\n",
    "  spider.get_page('http://code.tarena.com.cn/')\n",
    "\n",
    "\n",
    "# 111.177.183.198:9999\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
